
% Default to the notebook output style

    


% Inherit from the specified cell style.




    
\documentclass[11pt]{article}

    
    
    \usepackage[T1]{fontenc}
    % Nicer default font (+ math font) than Computer Modern for most use cases
    \usepackage{mathpazo}

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % We will generate all images so they have a width \maxwidth. This means
    % that they will get their normal width if they fit onto the page, but
    % are scaled down if they would overflow the margins.
    \makeatletter
    \def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
    \else\Gin@nat@width\fi}
    \makeatother
    \let\Oldincludegraphics\includegraphics
    % Set max figure width to be 80% of text width, for now hardcoded.
    \renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=.8\maxwidth]{#1}}
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionLabelFormat{nolabel}{}
    \captionsetup{labelformat=nolabel}

    \usepackage{adjustbox} % Used to constrain images to a maximum size 
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range 
    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    

    
    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatability definitions
    \def\gt{>}
    \def\lt{<}
    % Document parameters
    \title{regression\_bayesian}
    
    
    

    % Pygments definitions
    
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % Exact colors from NB
    \definecolor{incolor}{rgb}{0.0, 0.0, 0.5}
    \definecolor{outcolor}{rgb}{0.545, 0.0, 0.0}



    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

    \begin{document}
    
    
    \maketitle
    
    

    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}1}]:} \PY{o}{\PYZpc{}}\PY{k}{config} InlineBackend.figure\PYZus{}format = \PYZsq{}svg\PYZsq{} \PYZsh{} change output plot display format to \PYZsq{}svg\PYZsq{}
        
        \PY{c+c1}{\PYZsh{} import the required modules for this notebook}
        \PY{k+kn}{import} \PY{n+nn}{numpy}
        \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
        
        \PY{c+c1}{\PYZsh{} import the helper functions from the parent directory,}
        \PY{c+c1}{\PYZsh{} these help with things like graph plotting and notebook layout}
        \PY{k+kn}{import} \PY{n+nn}{sys}
        \PY{n}{sys}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{..}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{k+kn}{from} \PY{n+nn}{helper\PYZus{}functions} \PY{k}{import} \PY{o}{*}
        
        \PY{c+c1}{\PYZsh{} set things like fonts etc \PYZhy{} comes from helper\PYZus{}functions}
        \PY{n}{set\PYZus{}notebook\PYZus{}preferences}\PY{p}{(}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} add a show/hide code button \PYZhy{} also from helper\PYZus{}functions}
        \PY{n}{toggle\PYZus{}code}\PY{p}{(}\PY{n}{title} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{setup code}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}


    
    \begin{verbatim}
<IPython.core.display.HTML object>
    \end{verbatim}

    
    
    \begin{verbatim}
<IPython.core.display.HTML object>
    \end{verbatim}

    
    \subsection{Bayesian linear
regression}\label{bayesian-linear-regression}

We have seen \href{regression_regularisation.ipynb}{previously} how i)
regularisation can be intrepreted in terms of a probabilistic prior over
the regression weights, and ii) how MAP estimation of the weights
mitigates some of the effects of overfitting. However, the approaches we
have considered so far have not returned uncertainty estimates in the
weights. Uncertainty estimates are key when, for example, making
decisions and performing online incremental updates to the model.

In this section we will consider Bayesian approaches to regression that
return uncertainty in parameter estimates. The probabilisitc approach
involves two phases. First we explicitly define our assumptions about
how the data and parameters are generated. This is called the
probabilistic model. Second, we use the rules of probability to
manipulate the probabilistic model to perform the inferences we wish to
make. Let's walk through these two steps in detail.

\subsubsection{1. Probabilistic model}\label{probabilistic-model}

First we describe the probabilisitc model. You can think of this as a
probabilistic recipe (or probabilistic program) for sampling datasets
together with their underlying parameters. This recipe should encode
knowledge about what we believe a typical dataset might look like before
observing data.

In the current case the probabilistic programme samples the regression
weights from a Gaussian, forms the regression function, samples \(N\)
input locations and then samples \(N\) outputs. (We have assumed the
observation noise \(\sigma_y^2\) and prior variance on the weights
\(\sigma_{\mathbf{w}}^2\) are known).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  sample the weights
  \(\mathbf{w}^{(m)} \sim \mathcal{N}(\mathbf{0},\sigma_{\mathbf{w}}^2 \mathrm{I})\)
  for \(m=1...M\)
\item
  define the regression function
  \(f_{\mathbf{w}}^{(m)}(\mathbf{x})=\boldsymbol{\phi}(\mathbf{x})^\top \mathbf{w}^{(m)}\)
\item
  sample \(N\) input locations \(\mathbf{x}^{(m)}_n \sim p(\mathbf{x})\)
  for \(n=1...N\)
\item
  sample \(N\) output locations
  \(y_n |\mathbf{w}^{(m)},\mathbf{x}^{(m)}_n,\sigma_{y}^2 \sim \mathcal{N}(f^{(m)}_{\mathbf{w}}(\mathbf{x}^{(m)}_n),\sigma_{y}^2)\)
  for \(n=1...N\)
\end{enumerate}

Here are four datasets produced from this probabilistic model using
linear basis functions and scalar inputs:

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}2}]:} \PY{n}{D} \PY{o}{=} \PY{l+m+mi}{1} \PY{c+c1}{\PYZsh{} order of polynomial}
        \PY{n}{M} \PY{o}{=} \PY{l+m+mi}{4} \PY{c+c1}{\PYZsh{} number of samples of model}
        \PY{n}{N} \PY{o}{=} \PY{l+m+mi}{7} \PY{c+c1}{\PYZsh{} number of data points per model}
        
        \PY{n}{var\PYZus{}w} \PY{o}{=} \PY{l+m+mi}{1} \PY{c+c1}{\PYZsh{} a priori variance of weights}
        \PY{n}{var\PYZus{}y} \PY{o}{=} \PY{l+m+mf}{0.01} \PY{c+c1}{\PYZsh{} observation noise variance}
        
        \PY{c+c1}{\PYZsh{} input locations}
        \PY{n}{xs} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{linspace}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{100}\PY{p}{)} \PY{c+c1}{\PYZsh{} 100 points equispaced between 0 and 1}
        
        \PY{c+c1}{\PYZsh{} polynomial basis functions}
        \PY{n}{phi\PYZus{}pred} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{p}{[}\PY{p}{[}\PY{n}{x\PYZus{}} \PY{o}{*}\PY{o}{*} \PY{n}{d} \PY{k}{for} \PY{n}{d} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{D} \PY{o}{+} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{]} \PY{k}{for} \PY{n}{x\PYZus{}} \PY{o+ow}{in} \PY{n}{xs}\PY{p}{]}\PY{p}{)} 
        
        
        \PY{c+c1}{\PYZsh{} Gaussian basis functions}
        \PY{c+c1}{\PYZsh{} var\PYZus{}phi = 0.05;}
        \PY{c+c1}{\PYZsh{} phi\PYZus{}pred = np.array( [[ np.exp(\PYZhy{}1/(2*var\PYZus{}phi)*np.power(x\PYZus{}\PYZhy{}d/D,2))  for d in range(D + 1) ]  for x\PYZus{} in xs]) }
        \PY{c+c1}{\PYZsh{} phi\PYZus{}samp = np.array( [[ np.exp(\PYZhy{}1/(2*var\PYZus{}phi)*np.power(x\PYZus{}\PYZhy{}d/D,2))  for d in range(D + 1) ]  for x\PYZus{} in x\PYZus{}samp])}
        
        \PY{k}{for} \PY{n}{m} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{M}\PY{o}{+}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{:}
            
            \PY{c+c1}{\PYZsh{} input locations}
            \PY{n}{x\PYZus{}samp} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{uniform}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{n}{N}\PY{p}{)} 
        
            \PY{c+c1}{\PYZsh{} polynomial basis functions}
            \PY{n}{phi\PYZus{}samp} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{p}{[}\PY{p}{[}\PY{n}{x\PYZus{}} \PY{o}{*}\PY{o}{*} \PY{n}{d} \PY{k}{for} \PY{n}{d} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{D} \PY{o}{+} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{]} \PY{k}{for} \PY{n}{x\PYZus{}} \PY{o+ow}{in} \PY{n}{x\PYZus{}samp}\PY{p}{]}\PY{p}{)} 
        
        
            
            \PY{c+c1}{\PYZsh{} sample weights}
            \PY{n}{w} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{normal}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{np}\PY{o}{.}\PY{n}{power}\PY{p}{(}\PY{n}{var\PYZus{}w}\PY{p}{,} \PY{l+m+mf}{0.5}\PY{p}{)}\PY{p}{,} \PY{n}{D}\PY{o}{+}\PY{l+m+mi}{1}\PY{p}{)}
        
            \PY{c+c1}{\PYZsh{} plot function at input locations}
            \PY{n}{fs} \PY{o}{=} \PY{n}{phi\PYZus{}pred}\PY{o}{.}\PY{n}{dot}\PY{p}{(}\PY{n}{w}\PY{p}{)} \PY{c+c1}{\PYZsh{} output of the model at the points above}
            
            \PY{n}{y\PYZus{}samp} \PY{o}{=} \PY{n}{phi\PYZus{}samp}\PY{o}{.}\PY{n}{dot}\PY{p}{(}\PY{n}{w}\PY{p}{)} \PY{o}{+} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{normal}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{np}\PY{o}{.}\PY{n}{power}\PY{p}{(}\PY{n}{var\PYZus{}y}\PY{p}{,} \PY{l+m+mf}{0.5}\PY{p}{)}\PY{p}{,} \PY{n}{N}\PY{p}{)}
            
            \PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,}\PY{n}{M}\PY{p}{,}\PY{n}{m}\PY{p}{)}
            \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{xs}\PY{p}{,} \PY{n}{fs}\PY{p}{)} \PY{c+c1}{\PYZsh{} plot predictions}
            \PY{n}{plt}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{x\PYZus{}samp}\PY{p}{,} \PY{n}{y\PYZus{}samp}\PY{p}{,} \PY{n}{marker} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{x}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{color} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{red}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{c+c1}{\PYZsh{} plot predictions}
           
            \PY{n}{plt}\PY{o}{.}\PY{n}{xlim}\PY{p}{(}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mf}{0.1}\PY{p}{,} \PY{l+m+mf}{1.1}\PY{p}{]}\PY{p}{)}
            \PY{n}{plt}\PY{o}{.}\PY{n}{ylim}\PY{p}{(}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mf}{3.1}\PY{p}{,} \PY{l+m+mf}{3.1}\PY{p}{]}\PY{p}{)}
            \PY{k}{if} \PY{n}{m}  \PY{o+ow}{is} \PY{o+ow}{not} \PY{l+m+mi}{1}\PY{p}{:}
                \PY{n}{remove\PYZus{}axes}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{y}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
            
        \PY{n}{plt}\PY{o}{.}\PY{n}{tight\PYZus{}layout}\PY{p}{(}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
        
        \PY{n}{toggle\PYZus{}code}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_2_0.pdf}
    \end{center}
    { \hspace*{\fill} \\}
    
    
    \begin{verbatim}
<IPython.core.display.HTML object>
    \end{verbatim}

    
    The probabilistic model is a joint distribution over all of the random
variables:

\begin{align}
p(\mathbf{w},\mathbf{y},\mathbf{X} | \sigma_{\mathbf{w}}^2,\sigma_{y}^2) & = p(\mathbf{w}| \sigma_{\mathbf{w}}^2)  p(\mathbf{X}) p(\mathbf{y}|\mathbf{X},\sigma_{y}^2) = p(\mathbf{w} | \sigma_{\mathbf{w}}^2) \prod_{n=1}^N p(x_n) p(y_n |\mathbf{w},\mathbf{x}_n,\sigma_{y}^2)\\
& = \mathcal{N}(\mathbf{w} ; \mathbf{0},\sigma_{\mathbf{w}}^2 \mathrm{I}) \prod_{n=1}^N p(\mathbf{x}_n) \mathcal{N}(y_n; f^{(m)}_{\mathbf{w}}(\mathbf{x}),\sigma_{y}^2)
\end{align}

All aspects of this model can be critiqued:

The assumption of \textbf{independent Gaussian observation noise} can be
appropriate, e.g. if there are many independent noise sources and the
central limit theorem has kicked in, and it leads to analytic inference.
However, it may be inappropriate if the output noise is correlated or if
there are outliers in the data (e.g. see
\href{regression_linear.ipynb}{question 1B} and
\href{regression_regularisation.ipynb}{question 2}).

The \textbf{zero mean Gaussian prior over the weights} encodes the fact
that \emph{a priori} we expect the weight values to take values within a
few standard deviations \(\sigma_{\mathbf{w}}\) of zero. We will see in
a moment that the use of a Gaussian distribution leads to tractable
inference schemes. However, other distributions might be appropriate
depending on the circumstances. For example, you might have reason to
suspect that only a small number of the features \(\phi_d(\mathbf{x})\)
affect the output, in which case distributions that put more probability
mass at zero and in the tails than a Gaussian might be more appropriate.
Such distributions are called sparse distribtions and examples include
the \href{https://en.wikipedia.org/wiki/Laplace_distribution}{Laplace}
and
\href{https://en.wikipedia.org/wiki/Student\%27s_t-distribution}{Student's
t-distribution}.

Notice here that our probabilistic model includes a \textbf{distribution
over the input locations} are sampled. This is required to sample
datasets, but it is not something that we encountered when we
\href{regression_regularisation.ipynb}{interpreted regularisation in
terms of MAP inference in a probabilistic model}. We will see that the
distribution over the inputs does not affect the inference for the
weights. This is why we have not specified a distributional family for
\(p(x)\).

    \subsubsection{2.1 Probabilistic inference for the
weights}\label{probabilistic-inference-for-the-weights}

Now let's perform probabilistic inference for the weights. This involves
computing the probability of the weights given the observed inputs and
outputs
\(p(\mathbf{w}|\mathbf{y}, \mathbf{X}, \sigma_{\mathbf{w}}^2, \sigma_{y}^2)\),
or for shorthand the posterior distribution of the weights.

Applying the product rule to the probabilistic model we find that the
posterior can be computed by multiplying the prior
\(p(\mathbf{w}| \sigma_{\mathbf{w}}^2)\) (what we knew about the
parameters before seeing data) with the likelihood of the parameters
\(p(\mathbf{y}|\mathbf{X}, \mathbf{w}, \sigma_y^2)\) (what the data tell
us about the parameters), and renormalising to ensure the density
integrates to 1:

\begin{align}
p(\mathbf{w}|\mathbf{y}, \mathbf{X}, \sigma_{\mathbf{w}}^2, \sigma_{y}^2)  \propto p(\mathbf{w}| \sigma_{\mathbf{w}}^2)  p(\mathbf{y}|\mathbf{X}, \mathbf{w}, \sigma_y^2)
\end{align}

 Detailed derivation for the posterior over the weights

Starting from the posterior distribution,
\(p(\mathbf{w}|\mathbf{y}, \mathbf{X}, \sigma_{\mathbf{w}}^2, \sigma_{y}^2)\).
we first apply the product rule,

\begin{align}
p(\mathbf{w}|\mathbf{y}, \mathbf{X}, \sigma_{\mathbf{w}}^2, \sigma_{y}^2) = 
 \frac{1}{
 p(\mathbf{y}, \mathbf{X}| \sigma_{\mathbf{w}}^2, \sigma_{y}^2)
 }
 p(\mathbf{w},\mathbf{y}, \mathbf{X}| \sigma_{\mathbf{w}}^2, \sigma_{y}^2).
\end{align}

Now substituing in the joint distribution specified by the probabilistic
model yields

\begin{align}
p(\mathbf{w}|\mathbf{y}, \mathbf{X}, \sigma_{\mathbf{w}}^2, \sigma_{y}^2) & =
 \frac{1}{
 p(\mathbf{y}, \mathbf{X}| \sigma_{\mathbf{w}}^2, \sigma_{y}^2)
 } 
  p(\mathbf{w}| \sigma_{\mathbf{w}}^2) p(\mathbf{X}) p(\mathbf{y}|\mathbf{X}, \mathbf{w}, \sigma_y^2) 
  = 
  \frac{1}{
 p(\mathbf{y} | \mathbf{X}, \sigma_{\mathbf{w}}^2, \sigma_{y}^2)
 } 
  p(\mathbf{w}| \sigma_{\mathbf{w}}^2)  p(\mathbf{y}|\mathbf{X}, \mathbf{w}, \sigma_y^2) \\ 
  & \propto p(\mathbf{w}| \sigma_{\mathbf{w}}^2)  p(\mathbf{y}|\mathbf{X}, \mathbf{w}, \sigma_y^2).
\end{align}

In the last line we have dropped the term that does not depend on the
weights: this is a normalising constant that we can recompute later by
ensuring the distribution integrates to one.

The next step is to substitute the distributional forms for the prior
and the likelihood. The prior is a Gaussian distribution over the
weights. The likelihood also takes a Gaussian form when viewed as a
\emph{function of the weights}:

\[\begin{align}
p(\mathbf{w}| \sigma_{\mathbf{w}}^2) &= \frac{1}{(2\pi \sigma_{\mathbf{w}}^2)^{D/2}}\text{exp}\big(-\frac{1}{2\sigma_w^2}\mathbf{w}^\top \mathbf{w}\big)\\
p(\mathbf{y}|\mathbf{X}, \mathbf{w}, \sigma_y^2) &= \frac{1}{(2\pi \sigma_y^2)^{N/2}}\text{exp}\big(-\frac{1}{2\sigma_y^2}(\mathbf{y} - \boldsymbol{\Phi}\mathbf{w})^\top (\mathbf{y} - \boldsymbol{\Phi}\mathbf{w})\big)
\end{align}\]

Since the product of two Gaussians yield another Gaussian function the
posterior will also be a Gaussian distribution,

\begin{align}
p(\mathbf{w}|\mathbf{y}, \mathbf{X}, \sigma_{\mathbf{w}}^2, \sigma_{y}^2) = \mathcal{N}(\mathbf{w}; \mathbf{\mu}_{\mathbf{w} | \mathbf{y}, \mathbf{X} },\Sigma_{\mathbf{w} | \mathbf{y}, \mathbf{X} }).
\end{align}

where

\begin{align}
\Sigma_{\mathbf{w} | \mathbf{y}, \mathbf{X} }  = \left( \frac{1}{\sigma_y^2} \boldsymbol{\Phi}^\top \boldsymbol{\Phi} + \frac{1}{\sigma_{\mathbf{w}}^2} \mathrm{I} \right)^{-1} \;\;\; \text{and} \;\;\;
\mathbf{\mu}_{\mathbf{w} | \mathbf{y}, \mathbf{X} } =  \Sigma_{\mathbf{w} | \mathbf{y}, \mathbf{X} } \frac{1}{\sigma_y^2}  \boldsymbol{\Phi}^\top \mathbf{y}.
\end{align}

 Detailed derivation for the posterior mean and covariance

In order to find the posterior mean and covariance, we i) multiply
together the prior and likelihood and expand the result in terms of an
exponentiated quadratic in \(\mathbf{w}\), and then ii) compare
coefficients to identify the posterior mean and covariance.

Step (i): Multiplying prior and likelihood

\begin{align}
p(\mathbf{w}|\mathbf{y}, \mathbf{X}, \sigma_{\mathbf{w}}^2, \sigma_y^2) &\propto \text{exp}\big(-\frac{1}{2\sigma_y^2}(\mathbf{y} - \boldsymbol{\Phi}\mathbf{w})^\top (\mathbf{y} - \boldsymbol{\Phi}\mathbf{w}) -\frac{1}{2 \sigma_{\mathbf{w}}^2}\mathbf{w}^\top  \mathbf{w}  \big)\\
& \propto \text{exp}\left( - \frac{1}{2}\mathbf{w}^\top \left( \frac{1}{\sigma_y^2} \boldsymbol{\Phi}^\top \boldsymbol{\Phi} + \frac{1}{\sigma_{\mathbf{w}}^2} \mathrm{I} \right)\mathbf{w} + \frac{1}{\sigma_y^2} \mathbf{w}^\top \boldsymbol{\Phi}^\top \mathbf{y} \right) 
\end{align}

Step (ii): comparing coefficients to a Gaussian

\begin{align}
p(\mathbf{w}|\mathbf{y}, \mathbf{X}, \sigma_{\mathbf{w}}^2, \sigma_y^2) &= \mathcal{N}(\mathbf{w}; \mathbf{\mu}_{\mathbf{w} | \mathbf{y}, \mathbf{X} },\Sigma_{\mathbf{w} | \mathbf{y}, \mathbf{X} }), \\
& \propto \text{exp}\left( - \frac{1}{2}\mathbf{w}^\top \Sigma^{-1}_{\mathbf{w} | \mathbf{y}, \mathbf{X} }\mathbf{w} + \mathbf{w}^\top \Sigma^{-1}_{\mathbf{w} | \mathbf{y}, \mathbf{X} } \mathbf{\mu}_{\mathbf{w} | \mathbf{y}, \mathbf{X} } \right).
\end{align}

Hence the posterior covariance and mean are given by:

\begin{align}
\Sigma_{\mathbf{w} | \mathbf{y}, \mathbf{X} }  = \left( \frac{1}{\sigma_y^2} \boldsymbol{\Phi}^\top \boldsymbol{\Phi} + \frac{1}{\sigma_{\mathbf{w}}^2} \mathrm{I} \right)^{-1}, \;\;\;
\mathbf{\mu}_{\mathbf{w} | \mathbf{y}, \mathbf{X} } =  \Sigma_{\mathbf{w} | \mathbf{y}, \mathbf{X} } \frac{1}{\sigma_y^2}  \boldsymbol{\Phi}^\top \mathbf{y}.
\end{align}

In a moment we will derive the probabilistic approach to prediction.
Before we do this, let's take some time to consider the results above.

First, notice that the mean of the posterior distribution over the
weights can be expressed as

\[
\mathbf{\mu}_{\mathbf{w} | \mathbf{y}, \mathbf{X} }  = (\sigma^{-2}\boldsymbol{\Phi}^\top \boldsymbol{\Phi} + \lambda \mathbf{I})\boldsymbol{\Phi}^\top \mathbf{y}
\]

where \$\lambda = \sigma\^{}2\_\mathbf{w} / \sigma\^{}2\_y \$. This
recovers the solution from regularised least squares fitting which we
previously interpreted as finding the \emph{maximum a posteriori}
setting of the weights given the data,

\begin{align}
\mathbf{w}^{\text{MAP}} & = \underset{\mathbf{w}}{\mathrm{arg\,max}} \; p(\mathbf{w} | \mathbf{y},\mathbf{X},\sigma_y^2,\sigma_{\mathbf{w}}^2).
\end{align}

This all adds up because the posterior is Gaussian and the most probable
weight under a Gaussian is the mean value.

\begin{align}
\mathbf{w}^{\text{MAP}} & = \underset{\mathbf{w}}{\mathrm{arg\,max}} \; p(\mathbf{w} | \mathbf{y},\mathbf{X},\sigma_y^2,\sigma_{\mathbf{w}}^2) = \mathbf{\mu}_{\mathbf{w} | \mathbf{y}, \mathbf{X} } = \mathbb{E}_{p(\mathbf{w} | \mathbf{y},\mathbf{X},\sigma_y^2,\sigma_{\mathbf{w}}^2)}(\mathbf{w}).
\end{align}

Second, notice that the \textbf{prior} distribution and the
\textbf{posterior} distribution belong to the same family (i.e.
Gaussian). When a model has this property, the prior and likelihood are
said to be \textbf{conjugate}, or for short it is said to have a
\textbf{conjugate prior}. Conjugate priors lead to tractable and
convenient analytic posterior distributions.

    \subsubsection{2.2 Probabilistic inference for
prediction}\label{probabilistic-inference-for-prediction}

Now let's consider how to use probabilistic inference to make
predictions for an unseen output \(y^*\) at input location
\(\mathbf{x}^*\). The MAP and maximum likelihood methods use a point
estimate for the weights, \(\hat{\mathbf{w}}\), simply computing
\(p(y^* | \mathbf{x}^*, \hat{\mathbf{w}},\sigma_y^2,\sigma_{\mathbf{w}}^2\).
This is equivalent to assuning that the weights are known to take the
value \(\hat{\mathbf{w}}\). The full probabilistic approach considers
undertainty in \(\mathbf{w}\) and is therefore more complex. The full
solution is a probability distribution over the unseen output, give the
input and the training data,
\(p(y^* | \mathbf{x}^*, \mathbf{y},\mathbf{X},\sigma_y^2,\sigma_{\mathbf{w}}^2)\),
which can be computed by \[
p(y^* | \mathbf{x}^*, \mathbf{y},\mathbf{X},\sigma_y^2,\sigma_{\mathbf{w}}^2) = \int p(y^* | \mathbf{x}^*, \mathbf{w},\sigma_y^2) p(\mathbf{w}|\mathbf{y},\mathbf{X},\sigma_y^2,\sigma_{\mathbf{w}}^2) d\mathbf{w}.
\]

So, the predictive is formed by considering every possible setting of
the underlying weights, computing the associated prediction
\(p(y^* | \mathbf{x}^*, \mathbf{w})\), weighting this by the posterior
probability of the weight taking that value
\(p(\mathbf{w}|\mathbf{y},\mathbf{X},\sigma_y^2,\sigma_{\mathbf{w}}^2)\),
and averaging these weighted predictions together. The form of the
predictive distribution may seem intuitively obvious, but for a full
derivation see below.

 Detailed derivation for the predictive distribution

First we apply the sum rule to introduce the weight back into the
expression. The sum rule states \(p(A|C) = \int p(A,B|C) \text{d}B\) and
we use \$A = y\^{}* \$, \(B = \mathbf{w}\) and
\(C = \{x^*, \mathbf{y},\mathbf{X},\sigma_y^2,\sigma_{\mathbf{w}}^2\}\)
so

\begin{align}
p(y^* | \mathbf{x}^*, \mathbf{y},\mathbf{X},\sigma_y^2,\sigma_{\mathbf{w}}^2)  = \int p(y^*,\mathbf{w} | \mathbf{x}^*, \mathbf{y},\mathbf{X},\sigma_y^2,\sigma_{\mathbf{w}}^2) \mathrm{d} \mathbf{w} 
\end{align}

Second we apply the product rule. The product rule states
\(p(A,B|C) = p(B|C)p(A|B,C)\) and we use the same variable associations
as above to give

\begin{align}
p(y^* | \mathbf{x}^*, \mathbf{y},\mathbf{X},\sigma_y^2,\sigma_{\mathbf{w}}^2)  = \int p( \mathbf{w} | \mathbf{x}^*, \mathbf{y},\mathbf{X},\sigma_y^2,\sigma_{\mathbf{w}}^2) p(y^* | \mathbf{w} , \mathbf{x}^*, \mathbf{y},\mathbf{X},\sigma_y^2,\sigma_{\mathbf{w}}^2) \mathrm{d} \mathbf{w} 
\end{align}

Third, we use the structure of the probabilistic model to simplify the
above expression (more precisely the conditional independencies implied
by the model). By themselves, the test inputs \(\mathbf{x}^*\) provide
no information about the weights \(\mathbf{w}\) so
\(p( \mathbf{w} | \mathbf{x}^*, \mathbf{y},\mathbf{X},\sigma_y^2,\sigma_{\mathbf{w}}^2) = p( \mathbf{w} | \mathbf{y},\mathbf{X},\sigma_y^2,\sigma_{\mathbf{w}}^2)\).
Moreover, if the weights \(\mathbf{w}\) are known then the training data
provide no additional useful information for prediction so
\(p(y^* | \mathbf{w} , \mathbf{x}^*, \mathbf{y},\mathbf{X},\sigma_y^2,\sigma_{\mathbf{w}}^2) = p(y^* | \mathbf{w} , \mathbf{x}^*, \sigma_y^2,\sigma_{\mathbf{w}}^2)\).

Together these simplifications yield the expression for the predictive,

\begin{align}
p(y^* | \mathbf{x}^*, \mathbf{y},\mathbf{X},\sigma_y^2,\sigma_{\mathbf{w}}^2)  = \int p( \mathbf{w} |  \mathbf{y},\mathbf{X},\sigma_y^2,\sigma_{\mathbf{w}}^2) p(y^* | \mathbf{w} , \mathbf{x}^*, \sigma_y^2,\sigma_{\mathbf{w}}^2) \mathrm{d} \mathbf{w}.
\end{align}

There are long winded ways of performing the integral over the weights
required to compute the predictive. Fortunately there is one simple
route to the solution that involves no explicit integration at all.

The posterior
\(p( \mathbf{w} | \mathbf{y},\mathbf{X},\sigma_y^2,\sigma_{\mathbf{w}}^2)\)
is Gaussian. The test ouputs are a linear transformation of the weights
plus Gaussian noise. Since Gaussians are closed under linear transforms
and under the addition of Gaussian noise, the predictive distribution
will also be Gaussian,

\begin{align}
p(y^* | \mathbf{x}^*, \mathbf{y},\mathbf{X},\sigma_y^2,\sigma_{\mathbf{w}}^2)  = \mathcal{N}(y^* ; \mu_{y^*|\mathbf{y},\mathbf{X}},\sigma^2_{y^*| \mathbf{y},\mathbf{X}}).
\end{align}

The expectation and variance of the predictive are then fairly simple to
compute depending on the mean
\(\mu_{\mathbf{w}| \mathbf{y},\mathbf{X}}\) and covariance
\(\Sigma_{\mathbf{w}| \mathbf{y},\mathbf{X}}\) of the posterior
distribution over the weights and the basis functions at the test
locations \(\boldsymbol{\phi}_*\),

\begin{align}
\mu_{y^*|\mathbf{y},\mathbf{X}} = \boldsymbol{\phi}_{\ast}^\top \mu_{\mathbf{w}| \mathbf{y},\mathbf{X}}\\
\sigma^2_{y^*| \mathbf{y},\mathbf{X}} = \boldsymbol{\phi}_*^\top \Sigma_{\mathbf{w}| \mathbf{y},\mathbf{X}} \boldsymbol{\phi}_*  + \sigma_{y}^2.
\end{align}

 Detailed derivation for the mean and variance of the predictive
distribution

We know that the mean of the posterior predictive distribution is
defined as
\(\mu_{y^*|\mathbf{y},\mathbf{X}} = \mathbb{E}_{p(y^* | \mathbf{x}^*, \mathbf{y},\mathbf{X},\sigma_y^2,\sigma_{\mathbf{w}}^2)}[y^*]\).

We also know that we can write the posterior predictive distribution as

\begin{align}
p(y^* | \mathbf{x}^*, \mathbf{y},\mathbf{X},\sigma_y^2,\sigma_{\mathbf{w}}^2)  = \int p( \mathbf{w} |  \mathbf{y},\mathbf{X},\sigma_y^2,\sigma_{\mathbf{w}}^2) p(y^* | \mathbf{w} , \mathbf{x}^*, \sigma_y^2,\sigma_{\mathbf{w}}^2) \mathrm{d} \mathbf{w}.
\end{align}

So the mean of the poserior predictive can also be written

\begin{align}
\mu_{y^*|\mathbf{y},\mathbf{X}} =  \mathbb{E}_{p(y^* | \mathbf{x}^*, \mathbf{y},\mathbf{X},\sigma_y^2,\sigma_{\mathbf{w}}^2)}[y^*] = \mathbb{E}_{p( \mathbf{w} |  \mathbf{y},\mathbf{X},\sigma_y^2,\sigma_{\mathbf{w}}^2)}[ \mathbb{E}_{p(y^* | \mathbf{w} , \mathbf{x}^*, \sigma_y^2,\sigma_{\mathbf{w}}^2)}  [y^*] ]
\end{align}

The inner expectation is simple to compute
\(\mathbb{E}_{p(y^* | \mathbf{w} , \mathbf{x}^*, \sigma_y^2,\sigma_{\mathbf{w}}^2)} [y^*] = \boldsymbol{\phi}_*^\top \mathbf{w}\)
where we have used the fact that
\(p(y^* | \mathbf{w} , \mathbf{x}^*, \sigma_y^2,\sigma_{\mathbf{w}}^2) = \mathcal{N}(y^*; \boldsymbol{\phi}_*^\top \mathbf{w}, \sigma_y^2)\).

Now we can compute the outer expectation

\begin{align}
\mu_{y^*|\mathbf{y},\mathbf{X}} =  \mathbb{E}_{p( \mathbf{w} |  \mathbf{y},\mathbf{X},\sigma_y^2,\sigma_{\mathbf{w}}^2)}[ \boldsymbol{\phi}_*^\top \mathbf{w} ]= \boldsymbol{\phi}_*^\top\mathbb{E}_{p( \mathbf{w} |  \mathbf{y},\mathbf{X},\sigma_y^2,\sigma_{\mathbf{w}}^2)}[\mathbf{w}] = \boldsymbol{\phi}_*^\top \mu_{\mathbf{w}| \mathbf{y},\mathbf{X}}\\
\end{align}

The variance of the predictive distribution
\(\sigma^2_{y^*| \mathbf{y},\mathbf{X}} = \mathbb{E}_{p(y^* | \mathbf{x}^*, \mathbf{y},\mathbf{X},\sigma_y^2,\sigma_{\mathbf{w}}^2)}[(y^* )^2]- \mu_{y^*|\mathbf{y},\mathbf{X}}^2\)
can be computed in an identical way

\begin{align}
\sigma^2_{y^*| \mathbf{y},\mathbf{X}} & =  \mathbb{E}_{p( \mathbf{w} |  \mathbf{y},\mathbf{X},\sigma_y^2,\sigma_{\mathbf{w}}^2)}[ \mathbb{E}_{p(y^* | \mathbf{w} , \mathbf{x}^*, \sigma_y^2,\sigma_{\mathbf{w}}^2)}  (y^*)^2] - \mu_{y^*|\mathbf{y},\mathbf{X}}^2 \\
& = \mathbb{E}_{p( \mathbf{w} |  \mathbf{y},\mathbf{X},\sigma_y^2,\sigma_{\mathbf{w}}^2)}[ (\boldsymbol{\phi}_*^\top \mathbf{w})^2 +\sigma_y^2 ]  - \mu_{y^*|\mathbf{y},\mathbf{X}}^2\\ & = \mathbb{E}_{p( \mathbf{w} |  \mathbf{y},\mathbf{X},\sigma_y^2,\sigma_{\mathbf{w}}^2)}[ (\boldsymbol{\phi}_*^\top \mathbf{w})^2 ] - \mu_{y^*|\mathbf{y},\mathbf{X}}^2 +\sigma_y^2 \\
& = \mathbb{E}_{p( \mathbf{w} |  \mathbf{y},\mathbf{X},\sigma_y^2,\sigma_{\mathbf{w}}^2)}[ (\boldsymbol{\phi}_*^\top \mathbf{w} - \mu_{y^*|\mathbf{y},\mathbf{X}})^2 ] +\sigma_y^2\\
& = \boldsymbol{\phi}_*^\top \mathbb{E}_{p( \mathbf{w} |  \mathbf{y},\mathbf{X},\sigma_y^2,\sigma_{\mathbf{w}}^2)}[(\mathbf{w} - {\mu}_{\mathbf{w}| \mathbf{y},\mathbf{X}})(\mathbf{w} - {\mu}_{\mathbf{w}| \mathbf{y},\mathbf{X}})^\top] \boldsymbol{\phi}_*  + \sigma_y^2\\
& = \boldsymbol{\phi}_*^\top \Sigma_{\mathbf{w}| \mathbf{y},\mathbf{X}} \boldsymbol{\phi}_*  + \sigma_{y}^2
\end{align}

There's a more simple lens through which to view these results. Consider
the following result:

If \(z_3 = A z_1 + z_2\) where \$ z\_1
\sim \mathcal{N}(\mu\_1,\Sigma\_1)\$ and
\(z_2 \sim \mathcal{N}(0,\Sigma_2)\), then the marginal distribution
induced over \(z_3\) is
\(z_3 \sim \mathcal{N}(A \mu_1,A \Sigma_1 A^{\top} + \Sigma_2)\).

Now notice that this is precisely mirrors the result above. We had:
\(y^* = \boldsymbol{\phi}_*^\top \mathbf{w} + \epsilon'\) where
\(\mathbf{w} | \mathbf{y},\mathbf{X} \sim \mathcal{N}(\mu_{\mathbf{w}| \mathbf{y},\mathbf{X}}, \Sigma_{\mathbf{w}| \mathbf{y},\mathbf{X}})\)
and \(\epsilon' \sim \mathcal{N}(0,\sigma_y^2)\). So identifying:
\(A = \phi_*\), \$\mu\emph{1 = \mu}\{\mathbf{w}\textbar{}
\mathbf{y},\mathbf{X}\} \$,
\(\Sigma_1 = \Sigma_{\mathbf{w}| \mathbf{y},\mathbf{X}}\) and
\(\Sigma_2 = \sigma_y^2\) yields the same result as above.

Let's implement these results on the linear and non-linear datasets,
starting with the linear dataset.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}3}]:} \PY{n}{x\PYZus{}lin} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{load}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{reg\PYZus{}lin\PYZus{}x.npy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}  
        \PY{n}{y\PYZus{}lin} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{load}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{reg\PYZus{}lin\PYZus{}y.npy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{c+c1}{\PYZsh{} loading the linear regression dataset into numpy arrays}
        
        \PY{n}{var\PYZus{}w} \PY{o}{=} \PY{l+m+mi}{1}
        \PY{n}{var\PYZus{}y} \PY{o}{=} \PY{l+m+mf}{0.03}
        
        \PY{n}{phi} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{p}{[}\PY{p}{[}\PY{n}{x\PYZus{}} \PY{o}{*}\PY{o}{*} \PY{n}{d} \PY{k}{for} \PY{n}{d} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{)}\PY{p}{]} \PY{k}{for} \PY{n}{x\PYZus{}} \PY{o+ow}{in} \PY{n}{x\PYZus{}lin}\PY{p}{]}\PY{p}{)} \PY{c+c1}{\PYZsh{} X instantiated more elegantly here}
        
        \PY{n}{pre\PYZus{}w} \PY{o}{=} \PY{l+m+mi}{1}\PY{o}{/}\PY{n}{var\PYZus{}w} \PY{o}{*} \PY{n}{np}\PY{o}{.}\PY{n}{eye}\PY{p}{(}\PY{l+m+mi}{2}\PY{p}{)} \PY{c+c1}{\PYZsh{} prior covariance matrix to include in MAP solution}
        
        \PY{n}{S} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{linalg}\PY{o}{.}\PY{n}{inv}\PY{p}{(}\PY{p}{(}\PY{n}{phi}\PY{o}{.}\PY{n}{T}\PY{p}{)}\PY{o}{.}\PY{n}{dot}\PY{p}{(}\PY{n}{phi}\PY{p}{)} \PY{o}{/} \PY{n}{var\PYZus{}y} \PY{o}{+} \PY{n}{pre\PYZus{}w}\PY{p}{)} \PY{c+c1}{\PYZsh{} posterior distribution covariance matrix}
        \PY{n}{mu} \PY{o}{=} \PY{n}{S}\PY{o}{.}\PY{n}{dot}\PY{p}{(}\PY{n}{phi}\PY{o}{.}\PY{n}{T}\PY{p}{)}\PY{o}{.}\PY{n}{dot}\PY{p}{(}\PY{n}{y\PYZus{}lin}\PY{p}{)}\PY{o}{/}\PY{n}{var\PYZus{}y} \PY{c+c1}{\PYZsh{} MAP weights to use in mean(y*)}
        
        
        \PY{n}{x\PYZus{}pred} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{linspace}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{5}\PY{p}{,} \PY{l+m+mi}{5}\PY{p}{,} \PY{l+m+mi}{100}\PY{p}{)}
        \PY{n}{X\PYZus{}pred} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{p}{[}\PY{p}{[}\PY{n}{x\PYZus{}} \PY{o}{*}\PY{o}{*} \PY{n}{d} \PY{k}{for} \PY{n}{d} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{)}\PY{p}{]} \PY{k}{for} \PY{n}{x\PYZus{}} \PY{o+ow}{in} \PY{n}{x\PYZus{}pred}\PY{p}{]}\PY{p}{)}
        
        \PY{n}{mu\PYZus{}pred} \PY{o}{=} \PY{n}{X\PYZus{}pred}\PY{o}{.}\PY{n}{dot}\PY{p}{(}\PY{n}{mu}\PY{p}{)} \PY{c+c1}{\PYZsh{} calculate mean(y*)}
        \PY{n}{stdev\PYZus{}pred} \PY{o}{=} \PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{n}{X\PYZus{}pred}\PY{o}{.}\PY{n}{dot}\PY{p}{(}\PY{n}{S}\PY{p}{)} \PY{o}{*} \PY{n}{X\PYZus{}pred}\PY{p}{,} \PY{n}{axis} \PY{o}{=} \PY{l+m+mi}{1}\PY{p}{)} \PY{o}{+} \PY{n}{var\PYZus{}y}\PY{p}{)} \PY{o}{*}\PY{o}{*} \PY{l+m+mf}{0.5} \PY{c+c1}{\PYZsh{} calculate Var(y*)\PYZca{}0.5}
        
        \PY{n}{plt}\PY{o}{.}\PY{n}{fill\PYZus{}between}\PY{p}{(}\PY{n}{x\PYZus{}pred}\PY{p}{,} \PY{n}{mu\PYZus{}pred} \PY{o}{+} \PY{n}{stdev\PYZus{}pred}\PY{p}{,} \PY{n}{mu\PYZus{}pred} \PY{o}{\PYZhy{}} \PY{n}{stdev\PYZus{}pred}\PY{p}{,} \PY{n}{facecolor} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{grey}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{alpha} \PY{o}{=} \PY{l+m+mf}{0.5}\PY{p}{)} \PY{c+c1}{\PYZsh{} plot confidence intervals = +/\PYZhy{} Var(y*)\PYZca{}0.5}
        \PY{n}{plt}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{x\PYZus{}lin}\PY{p}{,} \PY{n}{y\PYZus{}lin}\PY{p}{,} \PY{n}{marker} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{x}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{color} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{red}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{c+c1}{\PYZsh{} plot data}
        \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{x\PYZus{}pred}\PY{p}{,} \PY{n}{mu\PYZus{}pred}\PY{p}{,} \PY{n}{color} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{black}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{c+c1}{\PYZsh{} plot mean(y*)}
        \PY{n}{beautify\PYZus{}plot}\PY{p}{(}\PY{p}{\PYZob{}}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{title}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Bayesian regression predictive}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{x}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZdl{}x\PYZdl{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{y}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZdl{}y\PYZdl{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{\PYZcb{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{xlim}\PY{p}{(}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{]}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{ylim}\PY{p}{(}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{]}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
        
        \PY{n}{toggle\PYZus{}code}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_6_0.pdf}
    \end{center}
    { \hspace*{\fill} \\}
    
    
    \begin{verbatim}
<IPython.core.display.HTML object>
    \end{verbatim}

    
    The solid black line shows the mean of the predictive distribution \$
\mu\_\{y\^{}*\textbar{}\mathbf{y},\mathbf{X}\}\$, and the grey area
shows one standard deviation around this
\(\pm \sigma_{y^*| \mathbf{y},\mathbf{X}}\). Notice how the uncertainty
grows away from the region where we have seen data. This seems
reasonable, as uncertainty in the gradient of a straight line fit would
have a larger effect as we move away from the data region.

Let's apply this method to the non-linear dataset.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}4}]:} \PY{c+c1}{\PYZsh{} exactly the same process with the linear case, except phi is different}
        
        \PY{n}{x\PYZus{}nonlin} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{load}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{reg\PYZus{}nonlin\PYZus{}x.npy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} 
        \PY{n}{y\PYZus{}nonlin} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{load}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{reg\PYZus{}nonlin\PYZus{}y.npy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{c+c1}{\PYZsh{} loading the non\PYZhy{}linear dataset}
        
        \PY{n}{var\PYZus{}w} \PY{o}{=} \PY{l+m+mi}{10}
        \PY{n}{var\PYZus{}y} \PY{o}{=} \PY{l+m+mf}{0.01}
        \PY{n}{D} \PY{o}{=} \PY{l+m+mi}{11}\PY{p}{;}
        
        \PY{n}{phi} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{p}{[}\PY{p}{[}\PY{n}{x\PYZus{}} \PY{o}{*}\PY{o}{*} \PY{n}{d} \PY{k}{for} \PY{n}{d} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{D} \PY{o}{+} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{]} \PY{k}{for} \PY{n}{x\PYZus{}} \PY{o+ow}{in} \PY{n}{x\PYZus{}nonlin}\PY{p}{]}\PY{p}{)}
        \PY{n}{pre\PYZus{}w} \PY{o}{=} \PY{l+m+mi}{1}\PY{o}{/}\PY{n}{var\PYZus{}w} \PY{o}{*} \PY{n}{np}\PY{o}{.}\PY{n}{eye}\PY{p}{(}\PY{n}{D}\PY{o}{+}\PY{l+m+mi}{1}\PY{p}{)} \PY{c+c1}{\PYZsh{} prior covariance matrix to include in MAP solution}
        
        \PY{n}{S} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{linalg}\PY{o}{.}\PY{n}{inv}\PY{p}{(}\PY{p}{(}\PY{n}{phi}\PY{o}{.}\PY{n}{T}\PY{p}{)}\PY{o}{.}\PY{n}{dot}\PY{p}{(}\PY{n}{phi}\PY{p}{)} \PY{o}{/} \PY{n}{var\PYZus{}y} \PY{o}{+} \PY{n}{pre\PYZus{}w}\PY{p}{)} \PY{c+c1}{\PYZsh{} posterior distribution covariance matrix}
        \PY{n}{mu} \PY{o}{=} \PY{n}{S}\PY{o}{.}\PY{n}{dot}\PY{p}{(}\PY{n}{phi}\PY{o}{.}\PY{n}{T}\PY{p}{)}\PY{o}{.}\PY{n}{dot}\PY{p}{(}\PY{n}{y\PYZus{}nonlin}\PY{p}{)}\PY{o}{/}\PY{n}{var\PYZus{}y} \PY{c+c1}{\PYZsh{} MAP weights to use in mean(y*)}
        
        \PY{n}{x\PYZus{}pred} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{linspace}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mf}{0.25}\PY{p}{,} \PY{l+m+mf}{1.1}\PY{p}{,} \PY{l+m+mi}{100}\PY{p}{)}
        \PY{n}{phi\PYZus{}pred} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{p}{[}\PY{p}{[}\PY{n}{x\PYZus{}} \PY{o}{*}\PY{o}{*} \PY{n}{d} \PY{k}{for} \PY{n}{d} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{D} \PY{o}{+} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{]} \PY{k}{for} \PY{n}{x\PYZus{}} \PY{o+ow}{in} \PY{n}{x\PYZus{}pred}\PY{p}{]}\PY{p}{)}
        
        \PY{n}{mu\PYZus{}pred} \PY{o}{=} \PY{n}{phi\PYZus{}pred}\PY{o}{.}\PY{n}{dot}\PY{p}{(}\PY{n}{mu}\PY{p}{)}
        \PY{n}{stdev\PYZus{}pred} \PY{o}{=} \PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{n}{phi\PYZus{}pred}\PY{o}{.}\PY{n}{dot}\PY{p}{(}\PY{n}{S}\PY{p}{)} \PY{o}{*} \PY{n}{phi\PYZus{}pred}\PY{p}{,} \PY{n}{axis} \PY{o}{=} \PY{l+m+mi}{1}\PY{p}{)} \PY{o}{+} \PY{n}{var\PYZus{}y}\PY{p}{)} \PY{o}{*}\PY{o}{*} \PY{l+m+mf}{0.5}
        
        \PY{n}{plt}\PY{o}{.}\PY{n}{fill\PYZus{}between}\PY{p}{(}\PY{n}{x\PYZus{}pred}\PY{p}{,} \PY{n}{mu\PYZus{}pred} \PY{o}{+} \PY{n}{stdev\PYZus{}pred}\PY{p}{,} \PY{n}{mu\PYZus{}pred} \PY{o}{\PYZhy{}} \PY{n}{stdev\PYZus{}pred}\PY{p}{,}
                         \PY{n}{facecolor} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{grey}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{alpha} \PY{o}{=} \PY{l+m+mf}{0.5}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{x\PYZus{}nonlin}\PY{p}{,} \PY{n}{y\PYZus{}nonlin}\PY{p}{,} \PY{n}{marker} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{x}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{color} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{red}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{x\PYZus{}pred}\PY{p}{,} \PY{n}{mu\PYZus{}pred}\PY{p}{,} \PY{n}{color} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{black}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{beautify\PYZus{}plot}\PY{p}{(}\PY{p}{\PYZob{}}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{title}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Bayesian regression predictive}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{x}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZdl{}x\PYZdl{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{y}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZdl{}y\PYZdl{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{\PYZcb{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{xlim}\PY{p}{(}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mf}{0.25}\PY{p}{,} \PY{l+m+mf}{1.1}\PY{p}{]}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
        
        \PY{n}{toggle\PYZus{}code}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_8_0.pdf}
    \end{center}
    { \hspace*{\fill} \\}
    
    
    \begin{verbatim}
<IPython.core.display.HTML object>
    \end{verbatim}

    
    In the next
\href{regression_bayesian-online-visualisations.ipynb}{notebook} we will
look at how to visualise and better understand the posterior
distribution over the weights using a process called \emph{online
learning}.

\subsection{Summary}\label{summary}

Having covered bayesian linear regression, you should now understand:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Why finding the \(\mathbf{w}\) using MAP with a gaussian likelihood
  and prior is equivalent to doing least-squares with \(\mathbf{L2}\)
  regularization
\item
  How to take a bayesian inference approach to regression problems,
  including how to calculate \(\mathbb{E}\)(y) and Var(y) for your
  fitted model.
\end{enumerate}

    \subsection{Questions}\label{questions}

1a. Consider the the Bayesian regression described above. Show that, in
addition to the number of datapoints \(N\), the posterior distribution
only requires the following statistics to be computed from the training
data,

\begin{align}
\mu^{(N)}_{d} &= \frac{1}{N}\sum_{n=1}^N \phi_d(\mathbf{x}_n) y_n, \;\; \text{and} \;\;
\Sigma^{(N)}_{d,d'} = \frac{1}{N}\sum_{n=1}^N \phi_d(\mathbf{x}_n) \phi_{d'}(\mathbf{x}_n). 
\end{align}

 Answer

Computing the posterior distribution requires the following two
statistics \(\boldsymbol{\Phi}^\top \mathbf{y}\) and
\(\boldsymbol{\Phi}^\top \boldsymbol{\Phi}\). Dividing these two
statistics by \(N\) and expanding them using index notation yields the
expressions above.

The fact that the inference depends only on the empirical average of a
small number of simple functions of the data is an example of
\textbf{suffiecnt statistics}. Sufficient statistics arise when
employing probabilistic models with elements that employ
\href{https://en.wikipedia.org/wiki/Exponential_family}{exponential
family distributions} like the Gaussian.

1b. Consider applying Bayesian regression on streaming data where one
datapoint \(\{ \mathbf{x}_n, y_n\}\) arrives at a time and the posterior
is continually updated as data come in.

Derive an update where the statistics (\(\mu^{(N)}_{d}\) and
\(\Sigma^{(N)}_d\)) are recomputed using the old values of the statitics
(\(\mu^{(N-1)}_{d}\) and \(\Sigma^{(N-1)}_d\)) and the current datapoint
(\(\{ \mathbf{x}_n, y_n\}\)).

What advantage does this have for very long data streams
\(N \rightarrow \infty\)?

 Answer

\begin{verbatim}
Consider the update for $\mu^{(N)}_{d}$. Splitting out the contribution from the $N$th datapoint, we have  
\end{verbatim}

\begin{align}
\mu^{(N)}_{d} &= \frac{1}{N}\sum_{n=1}^N \phi_d(\mathbf{x}_n) y_n = \frac{1}{N} \left(\phi_d(\mathbf{x}_N) y_N + \sum_{n=1}^{N-1} \phi_d(\mathbf{x}_n) y_n \right )\\ 
    &  = \frac{1}{N} \left(\phi_d(\mathbf{x}_N) y_N + \frac{N-1}{N-1}\sum_{n=1}^{N-1} \phi_d(\mathbf{x}_n) y_n \right)\\
    &  = \frac{1}{N} \phi_d(\mathbf{x}_N) y_N + \frac{N-1}{N} \mu^{(N-1)}_d
\end{align}

This is the idea of a 'running average'. Similarly for
\(\Sigma^{(N)}_{d,d'}\)

\begin{align}
\Sigma^{(N)}_{d,d'} &= \frac{1}{N} \phi_d(\mathbf{x}_N) \phi_{d'}(\mathbf{x}_N) + \frac{N-1}{N} \Sigma^{(N-1)}_{d,d'}. 
\end{align}

These updates do not require the entire dataset to be retained. They
just require the old statistics and the current datapoint, which can be
much more efficient in terms of memory. This idea relates to
\href{regression_bayesian-online-visualisations.ipynb}{online
inference}.


    % Add a bibliography block to the postdoc
    
    
    
    \end{document}
