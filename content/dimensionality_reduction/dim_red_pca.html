
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>4.1 Principal component analysis &#8212; Probabilistic Modelling and Inference</title>
    
  <link rel="stylesheet" href="../../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.e7340bb3dbd8dde6db86f25597f54a1b.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom_style.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.7d483ff0a819d6edff12ce0b1ead3928.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../index.html">
  
  <img src="../../_static/logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Probabilistic Modelling and Inference</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../home.html">
   Online Inference Textbook
  </a>
 </li>
</ul>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../regression/regression-intro.html">
   Regression
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../regression/regression-linear.html">
     Linear regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../regression/regression-nonlinear.html">
     Non-linear basis regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../regression/regression-overfitting.html">
     Overfitting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../regression/regression-regularisation.html">
     Regularisation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../regression/regression-bayesian.html">
     Bayesian Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../regression/regression-bayesian-online-visualisations.html">
     Bayesian Online Learning
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../classification/classification-intro.html">
   Classification
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../classification/classification-logistic-regression-model.html">
     Logistic classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../classification/classification-logistic-regression-ML-fitting.html">
     Maximum likelihood fitting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../classification/classification-gradient-case-study.html">
     Classification case study
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../classification/classification-multiclass.html">
     Multi-class classification
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="dim-red-intro.html">
   Dimensionality Reduction
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/content/dimensionality_reduction/dim_red_pca.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->


            <!-- Full screen (wrap in <a> to have style consistency -->
            <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                    data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                    title="Fullscreen mode"><i
                        class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/cambridge-mlg/online_textbook/master?urlpath=tree/./content/dimensionality_reduction/dim_red_pca.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = &#39;svg&#39; # change output plot display format to &#39;svg&#39;

<span class="c1"># import the required modules for this notebook</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># import the helper functions from the parent directory,</span>
<span class="c1"># these help with things like graph plotting and notebook layout</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;..&#39;</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">helper_functions</span> <span class="kn">import</span> <span class="o">*</span>

<span class="c1"># set things like fonts etc - comes from helper_functions</span>
<span class="n">set_notebook_preferences</span><span class="p">()</span>

<span class="c1"># add a show/hide code button - also from helper_functions</span>
<span class="n">toggle_code</span><span class="p">(</span><span class="n">title</span> <span class="o">=</span> <span class="s2">&quot;import functions&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
    <style>
  .output {
    font-family: ariel;
    align-items: normal;
    text-align: normal;
}

div.output_svg div { margin : auto; }
.div.output_area.MathJax_Display{ text-align: center; }
div.text_cell_render { font-family: sans-serif; }

details {
    margin: 20px 0px;
    padding: 0px 10px;
    border-radius: 3px;
    border-style: solid;
    border-color: black;
    border-width: 2px;
}
details div{padding: 20px 30px;}
details summary{font-size: 18px;}

table {
     margin: calc(auto + 10px) !important;
     border: solid !important;
 }

 th, td {
    text-align: left !important;
 }

 .further_box {
    background-color:rgb(230, 230, 230);
    border-style: solid;
    margin: 10px 10px 10px 0px;
    padding: 10px;
    left:calc(auto - 20px);
 }

 .question_box {
    background-color:rgb(255, 255, 225);
    border-style: solid;
    margin: 10px 10px 10px 0px;
    padding: 10px;
    left:calc(auto - 20px);
 }
    </style>
     <input type="submit" value='Home' class='home_button' onclick='window.location="../index.html"' style='float: right; margin-right: 40px;'>
    <script>
    $('.home_button').not(':first').remove();
    $(".home_button").insertBefore($("div.cell").first());
    $('div.input.init_hidden').hide()
    $('div.input.init_shown').show()
    $('.toggle_button').each(function( index, element ) {
       var prefix;
       if (this.classList.contains('init_show')) {
           prefix = 'Show '
       }
       else if (this.classList.contains('init_hide')) {
           prefix = 'Hide '
       };
       $(this).val(prefix + $(this).val().substr($(this).val().indexOf(" ") + 1))
    });
    IPython.OutputArea.prototype._should_scroll = function(lines) {
        return false;
    }
    </script>
</div><div class="output text_html">
    <script>
      function get_new_label(butn, hide) {
          var shown = !($(hide).is(':visible'))
          var title = $(butn).val().substr($(butn).val().indexOf(" ") + 1)
          return ((shown) ? 'Hide ' : 'Show ') + title
      }
      function code_toggle(butn, hide) {
          $(butn).val(get_new_label(butn,hide));
          $(hide).slideToggle();
      };
    </script>
    <input type="submit" value='initiated' class='toggle_button'>
    <script>
        var hidden_cells = $(".toggle_button[value='initiated']").parents('div.cell').prevAll().addBack().find('div.input').slice(-1)
        $(".toggle_button[value='initiated']").click(function(){            
            code_toggle(this, hidden_cells)
        }); 

$(".toggle_button[value='initiated']").parents("div.output_area").insertBefore($(".toggle_button[value='initiated']").parents("div.output").find('div.output_area').first());
    var shown = $(".toggle_button[value='initiated']").parents("div.cell.code_cell").find('div.input').is(':visible');
    var title = ((shown) ? 'Hide ' : 'Show ') + 'import functions'; 
     $(".toggle_button[value='initiated']").addClass("init_show");
            hidden_cells.addClass("init_hidden");  $(".toggle_button[value='initiated']").val(title);
        </script></div></div>
</div>
<div class="section" id="principal-component-analysis">
<h1>4.1 Principal component analysis<a class="headerlink" href="#principal-component-analysis" title="Permalink to this headline">¶</a></h1>
<p>In the <span class="xref myst">intro</span> we mentioned that in certain datasets, it might be useful to (i) discard low variance, uninformative features of the data to simplify the problem and model or to (ii) find the directions of highest variance to determine the most descriptive features of the data. These two goals point at two correpsonding approaches for dimensionality reduction, which turn out to be equivalent. The first amounts to a basis rotation and disposal of some dimensions, picked such that the sum-of-squares error from the original data is minimised <span class="math notranslate nohighlight">\(-\)</span> this is the formulation of reconstruction error minimisation. In the second approach, we discard a number of directions along which the data variance is low, retaining only directions of high variance <span class="math notranslate nohighlight">\(-\)</span> this is the formulation of variance maximisation. When using a sum-of-squares as the reconstruction error, the minimum error and maximum variance approaches are equivalent and are really the same method (which we will show later), called <strong>principal component analysis</strong> or PCA.</p>
<p>Starting with error minimisation, suppose <span class="math notranslate nohighlight">\(\{\mathbf{u}_d\}^D_{d = 1}\)</span> is a complete <em>orthonormal</em> basis, with which we can express any datapoint <span class="math notranslate nohighlight">\(\mathbf{x}_n\)</span> as a linear combination of these vectors:</p>
<p>\begin{align}
\mathbf{x}<em>n &amp;= \sum^D</em>{d = 1} a_{nd} \mathbf{u}_d\
\end{align}</p>
<p>Where <span class="math notranslate nohighlight">\(D\)</span> is the number of dimensions in the dataset. Now let’s take <span class="math notranslate nohighlight">\(M &lt; D\)</span> to be the number of dimensions we are reducing to (therefore <span class="math notranslate nohighlight">\(D-M\)</span> is the number of dimensions we are removing ). We can now write:</p>
<p>\begin{align}
\mathbf{x}<em>n =  \sum^M</em>{d = 1} a_{nd} \mathbf{u}<em>d + \sum^D</em>{d = M + 1} a_{nd} \mathbf{u}_d\
\end{align}</p>
<p>The first sum here represents the orthogonal projection of the original datapoint onto the lower-dimensional subspace (as this can be expressed by the first <span class="math notranslate nohighlight">\(M\)</span>  basis vectors), and the second sum represents the vector between the original datapoint and the new datapoint. Taking the first sum as our approximation <span class="math notranslate nohighlight">\(\mathbf{x}_n^\star\)</span> of <span class="math notranslate nohighlight">\(\mathbf{x}_n\)</span> in our lower dimensional space we have:</p>
<p>\begin{align}
\mathbf{x}<em>n^\star =  \sum^M</em>{d = 1} a_{nd} \mathbf{u}_d\
\end{align}</p>
<p>Our mean squared reconstruction error is simply the mean Euclidean distance between each <span class="math notranslate nohighlight">\(\mathbf{x}_n\)</span> and <span class="math notranslate nohighlight">\(\mathbf{x}_n^\star\)</span>:</p>
<p>\begin{align}
E_{rms} &amp;= \frac{1}{N}\sum^N_{n = 1}\bigg[\sum^D_{d = M + 1} a_{nd} \mathbf{u}<em>d\bigg]^\top \bigg[\sum^D</em>{d = M + 1} a_{nd} \mathbf{u}<em>d\bigg] = \frac{1}{N}\sum^N</em>{n = 1} \big|\mathbf{x}_n - \mathbf{x}_n^\star \big|^2\
\end{align}</p>
<p>and after some manipulation we can write <span class="math notranslate nohighlight">\(-\)</span> you can try this as an excercise:</p>
<p>\begin{align}
E_{rms} &amp;= \sum^D_{d = M + 1} \mathbf{u}_d^\top \mathbf{S} \mathbf{u}_d\
~\
\end{align}</p>
<p>Where <span class="math notranslate nohighlight">\(\mathbf{S}\)</span> is the covariance matrix of the data defined by:</p>
<p>\begin{align}
\mathbf{S} &amp;= \frac{1}{N}\sum^N_{n = 1}(\mathbf{x}_n - \bar{\mathbf{x}})(\mathbf{x}_n - \bar{\mathbf{x}})^\top\
\end{align}</p>
<details>
<summary>Reconstruction error in detail</summary>
<div>
<p>\begin{align}
E_{rms} &amp;= \frac{1}{N}\sum^N_{n = 1} \big|\mathbf{x}<em>n - \mathbf{x}<em>n^\star \big|^2\
~\
&amp;= \frac{1}{N}\sum^N</em>{n = 1} \bigg[\sum^D</em>{d = M + 1} a_{nd} \mathbf{u}<em>d\bigg]^2\
~\
&amp;=  \frac{1}{N}\sum^N</em>{n = 1}\bigg[\sum^D_{d = M + 1} a_{nd} \mathbf{u}<em>d\bigg]^\top \bigg[\sum^D</em>{d = M + 1} a_{nd} \mathbf{u}<em>d\bigg]\
~\
&amp;=  \frac{1}{N}\sum^N</em>{n = 1}\sum^D_{d = M + 1} a_{nd}^2, \text{ (using the basis orthonormality)}\
~\
&amp;=  \frac{1}{N}\sum^N_{n = 1}\sum^D_{d = M + 1} (\mathbf{u}_d^\top (\mathbf{x}_n - \bar{\mathbf{x}}))((\mathbf{x}_n - \bar{\mathbf{x}})^\top\mathbf{u}<em>d), \text{ (using } a</em>{nd} = \mathbf{u}_d^\top (\mathbf{x}_n - \bar{\mathbf{x}}<em>n))\
~\
&amp;=  \sum^D</em>{d = M + 1} \mathbf{u}_d^\top \mathbf{S} \mathbf{u}_d, \text{ (using the definition of } \mathbf{S})\
~\
\end{align}</p>
</div>
</details>
<p>Now we seek to minimise <span class="math notranslate nohighlight">\(E_{rms}\)</span> with respect to <span class="math notranslate nohighlight">\(\mathbf{u}_d\)</span>. Noting that <span class="math notranslate nohighlight">\(||\mathbf{u}_d|| = 1\)</span> (as it is orthonormal) and using a Lagrange multiplier, we minimize:</p>
<p>\begin{align}
E = E_{rms} - \lambda_d(\mathbf{u}_d^\top \mathbf{u}<em>d - 1) &amp;= \bigg[\sum^D</em>{d = M + 1} \mathbf{u}_d^\top \mathbf{S} \mathbf{u}_d \bigg] - \lambda_d(\mathbf{u}_d^\top \mathbf{u}_d - 1)\
\end{align}</p>
<p>with respect to <span class="math notranslate nohighlight">\(\mathbf{u}_d\)</span> to obtain the result <span class="math notranslate nohighlight">\(-\)</span> again you can try this as an excercise:</p>
<p>\begin{align}
\boxed{\mathbf{S} \mathbf{u}_d = \lambda_d\mathbf{u}_d}\
\end{align}</p>
<details>
<summary>Extremisation in detail</summary>
<div>
Here is a detailed derivation for the result \\(\mathbf{S} \mathbf{u}_d = \lambda_d\mathbf{u}_d\\), with explicit summations.
<p>\begin{align}
\bigg(\frac{\partial E}{\partial \mathbf{u}<em>d}\bigg)<em>i &amp;= \frac{\partial }{\partial \mathbf{u}</em>{d, i}} \Bigg[ \bigg[\sum^D</em>{n = M + 1} \mathbf{u}<em>n^\top \mathbf{S} \mathbf{u}<em>n \bigg] - \lambda_d(\mathbf{u}<em>d^\top \mathbf{u}<em>d - 1)\Bigg]\
~\<br />
&amp;= \frac{\partial }{\partial \mathbf{u}</em>{d, i}} \Bigg[\sum^D</em>{n = M + 1} \sum^D</em>{j = 1}\sum^D</em>{k = 1} \mathbf{u}<em>{n, j} \mathbf{S}</em>{j, k} \mathbf{u}<em>{n, k} - \lambda_d\bigg[ \sum^D</em>{j = 1}\mathbf{u}<em>{d, j} \mathbf{u}</em>{d, j} - 1\bigg] \Bigg]\
~\<br />
&amp;= 2 \Bigg[\sum^D_{j = 1}\sum^D_{k = 1} \frac{\partial \mathbf{u}<em>{d, j}} {\partial \mathbf{u}</em>{d, i}}\mathbf{S}<em>{j, k} \mathbf{u}</em>{d, k} - \lambda_d\sum^D_{j = 1} \frac{\partial \mathbf{u}<em>{d, j}}{\partial \mathbf{u}</em>{d, i}\mathbf{u}<em>{d, j}}\Bigg]\
~\<br />
&amp;= 2 \Bigg[\sum^D</em>{k = 1} \delta_{ij} \mathbf{S}<em>{j, k} \mathbf{u}</em>{d, k} - \lambda_d\sum^D_{j = 1} \mathbf{u}<em>{d, j} \delta</em>{ij} \Bigg]\
~\<br />
&amp;= 2 \Bigg[\sum^D_{k = 1} \mathbf{S}<em>{i, k}\mathbf{u}</em>{d, k} - \lambda_d \mathbf{u}_{d, i}\Bigg]\
\end{align}</p>
<p>Setting the derivative to <span class="math notranslate nohighlight">\(0\)</span>:</p>
<p>\[
\bigg(\frac{\partial E}{\partial \mathbf{u}<em>d}\bigg)<em>i = 0\
~\
\sum^D</em>{k = 1} \mathbf{S}</em>{i, k}\mathbf{u}<em>{d, k} - \lambda_d \mathbf{u}</em>{d, i} = 0\
~\
~\
\mathbf{S}\mathbf{u}<em>{d} - \lambda_d\mathbf{u}</em>{d} = 0\
\]</p>
<p>Arriving at the result:
\[
\boxed{\mathbf{S}\mathbf{u}<em>{d} = \lambda_d\mathbf{u}</em>{d}}\
\]</p>
</div>
</details>
<p>Determining <span class="math notranslate nohighlight">\(\mathbf{u}_d\)</span> has therefore turned into an eigenproblem. The <span class="math notranslate nohighlight">\(\mathbf{u}_d\)</span>’s which minimize the reconstruction loss are eigenvectors of <span class="math notranslate nohighlight">\(\mathbf{S}\)</span>. In addition, each of the corresponding eigenvalues <span class="math notranslate nohighlight">\(\lambda_d\)</span> is equal to the reconstruction loss due to discarding <span class="math notranslate nohighlight">\(\mathbf{u}_d\)</span>:</p>
<p>\begin{align}
\lambda_d &amp;= \mathbf{u}_d^\top\mathbf{S}\mathbf{u}<em>d =  \frac{1}{N}\sum^N</em>{n = 1} \mathbf{u}_d^\top(\mathbf{x}<em>n - \bar{\mathbf{x}})(\mathbf{x}<em>n - \bar{\mathbf{x}})^\top \mathbf{u}<em>d\
~\
\implies \sum</em>{d = M +1}^D \lambda_d &amp;= E =  \frac{1}{N}\sum</em>{d = M +1}^D\sum^N</em>{n = 1} \mathbf{u}_d^\top(\mathbf{x}_n - \bar{\mathbf{x}})(\mathbf{x}_n - \bar{\mathbf{x}})^\top \mathbf{u}_d\
\end{align}</p>
<p>which is a pleasing result. We can implement PCA straightforwardly by solving the eigenproblem <span class="math notranslate nohighlight">\(\mathbf{S} \mathbf{u}_d = \lambda_d\mathbf{u}_d\)</span>, and retaining the dimensions <span class="math notranslate nohighlight">\(\mathbf{u}_d\)</span> with the highest eigenvalues <span class="math notranslate nohighlight">\(-\)</span> discarding low eigenvalues means low reconstruction loss. Before that however, we will show the equivalence between reconstruction loss minimisation and variance maximisation. The latter amounts to selecting <span class="math notranslate nohighlight">\(M\)</span> orthogonal directions such that the variance of the dataset in these directions is maximal:</p>
<p>\begin{align}
\text{Var}<em>{1:M}({\mathbf{x}}) &amp;=  \frac{1}{N}\sum^N</em>{n = 1}\bigg[\sum^M_{d = 1} a_{nd} \mathbf{u}<em>d \bigg]^2\
~\
&amp;=  \frac{1}{N} \sum^N</em>{n = 1}\bigg[\sum^M_{d = 1} a_{nd} \mathbf{u}<em>d \bigg]^\top \bigg[\sum^M</em>{d = 1} a_{nd} \mathbf{u}_d \bigg]\
\end{align}</p>
<p>The total variance of the dataset, <span class="math notranslate nohighlight">\(\text{Var}_{1:D}(\{\mathbf{x}\})\)</span>, can be expressed as</p>
<p>\begin{align}
\text{Var}<em>{1:D}({\mathbf{x}}) &amp;=  \frac{1}{N}\sum^N</em>{n = 1}\bigg[\sum^D_{d = 1} a_{nd} \mathbf{u}<em>d \bigg]^2\
~\
&amp;=  \frac{1}{N}\sum^N</em>{n = 1}\Bigg[\bigg[\sum^M_{d = 1} a_{nd} \mathbf{u}<em>d \bigg]^2 + \bigg[\sum^D</em>{d = M + 1} a_{nd} \mathbf{u}<em>d \bigg]^2\Bigg]\
~\
&amp;= \text{Var}</em>{1:M}({\mathbf{x}}) + \text{Var}_{M:D}({\mathbf{x}})\
\end{align}</p>
<p>where we have used the orthogonality of the basis vectors <span class="math notranslate nohighlight">\(\mathbf{u}_d\)</span>. We can read off that the second term <span class="math notranslate nohighlight">\(\text{Var}_{M:D}(\{\mathbf{x}\})\)</span> is equal to the rms reconstruction loss found earlier:</p>
<p>\[
\text{Var}<em>{M:D}({\mathbf{x}}) = E</em>{rms}
\]</p>
<p>Considering that <span class="math notranslate nohighlight">\(\text{Var}_{1:D}(\{\mathbf{x}\})\)</span> is constant and independent of the choice of basis, we see that maximizing the variance <span class="math notranslate nohighlight">\(\text{Var}_{1:M}(\{\mathbf{x}\})\)</span> is equivalent to minimising the reconstruction loss <span class="math notranslate nohighlight">\(\text{Var}_{M:D}(\{\mathbf{x}\})\)</span>:</p>
<p>\begin{align}
\boxed{\text{Reconstruction loss minimisation}\Longleftrightarrow
\text{Variance maximisation}}
\end{align}</p>
<p>To make the equivalence even more explicit, consider that the directions of maximum (minimum) reconstruction error are those of maximum (minimum) variance. It is also straightforward to show the reconstruction error <span class="math notranslate nohighlight">\(\lambda_d\)</span> due to discarding <span class="math notranslate nohighlight">\(\mathbf{u}_d\)</span>, is equal to the dataset variance along <span class="math notranslate nohighlight">\(\mathbf{u}_d\)</span>.</p>
<p>Let’s write down a function which applies PCA to a dataset of arbitrary dimensionality.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">PCA</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    
    <span class="n">S</span> <span class="o">=</span> <span class="p">((</span><span class="n">x</span> <span class="o">-</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">))</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">))</span><span class="o">/</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># defining S as a function of x</span>
    
    <span class="n">eig_values</span><span class="p">,</span> <span class="n">eig_vectors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eig</span><span class="p">(</span><span class="n">S</span><span class="p">)</span> <span class="c1"># solving the eigenproblem</span>
    
    <span class="n">sort_idx</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="n">eig_values</span><span class="p">)</span><span class="o">.</span><span class="n">argsort</span><span class="p">()</span> 
    
    <span class="n">eig_values</span><span class="p">,</span> <span class="n">eig_vectors</span> <span class="o">=</span> <span class="n">eig_values</span><span class="p">[</span><span class="n">sort_idx</span><span class="p">],</span> <span class="n">eig_vectors</span><span class="p">[:,</span> <span class="n">sort_idx</span><span class="p">]</span>
    
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">real</span><span class="p">(</span><span class="n">eig_values</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">real</span><span class="p">(</span><span class="n">eig_vectors</span><span class="p">)</span>

<span class="n">toggle_code</span><span class="p">(</span><span class="n">title</span> <span class="o">=</span> <span class="s2">&quot;PCA algorithm&quot;</span><span class="p">,</span> <span class="n">on_load_hide</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
    <script>
      function get_new_label(butn, hide) {
          var shown = !($(hide).is(':visible'))
          var title = $(butn).val().substr($(butn).val().indexOf(" ") + 1)
          return ((shown) ? 'Hide ' : 'Show ') + title
      }
      function code_toggle(butn, hide) {
          $(butn).val(get_new_label(butn,hide));
          $(hide).slideToggle();
      };
    </script>
    <input type="submit" value='initiated' class='toggle_button'>
    <script>
        var hidden_cells = $(".toggle_button[value='initiated']").parents('div.cell').prevAll().addBack().find('div.input').slice(-1)
        $(".toggle_button[value='initiated']").click(function(){            
            code_toggle(this, hidden_cells)
        }); 

$(".toggle_button[value='initiated']").parents("div.output_area").insertBefore($(".toggle_button[value='initiated']").parents("div.output").find('div.output_area').first());
    var shown = $(".toggle_button[value='initiated']").parents("div.cell.code_cell").find('div.input').is(':visible');
    var title = ((shown) ? 'Hide ' : 'Show ') + 'PCA algorithm'; 
     $(".toggle_button[value='initiated']").addClass("init_hide");
            hidden_cells.addClass("init_shown");  $(".toggle_button[value='initiated']").val(title);
        </script></div></div>
</div>
<p>It’s all straightforward from now on, as we can use this handy function to do PCA in a single call.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;corr_data_2d.npy&#39;</span><span class="p">)</span> <span class="c1"># load the 2d correlated dataset</span>

<span class="n">eig_values</span><span class="p">,</span> <span class="n">eig_vectors</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># perform PCA and return results</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">marker</span> <span class="o">=</span> <span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;red&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">arrow</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">eig_vectors</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">eig_vectors</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">width</span> <span class="o">=</span> <span class="mf">0.05</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">arrow</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">eig_vectors</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">eig_vectors</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">width</span> <span class="o">=</span> <span class="mf">0.05</span><span class="p">)</span>
<span class="n">beautify_plot</span><span class="p">({</span><span class="s2">&quot;title&quot;</span><span class="p">:</span><span class="s2">&quot;PCA on the $2$D dataset&quot;</span><span class="p">,</span> <span class="s2">&quot;x&quot;</span><span class="p">:</span><span class="s2">&quot;$x_1$&quot;</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">:</span><span class="s2">&quot;$x_2$&quot;</span><span class="p">})</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">toggle_code</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/dim_red_pca_4_0.svg" src="../../_images/dim_red_pca_4_0.svg" /><div class="output text_html">
    <script>
      function get_new_label(butn, hide) {
          var shown = !($(hide).is(':visible'))
          var title = $(butn).val().substr($(butn).val().indexOf(" ") + 1)
          return ((shown) ? 'Hide ' : 'Show ') + title
      }
      function code_toggle(butn, hide) {
          $(butn).val(get_new_label(butn,hide));
          $(hide).slideToggle();
      };
    </script>
    <input type="submit" value='initiated' class='toggle_button'>
    <script>
        var hidden_cells = $(".toggle_button[value='initiated']").parents('div.cell').prevAll().addBack().find('div.input').slice(-1)
        $(".toggle_button[value='initiated']").click(function(){            
            code_toggle(this, hidden_cells)
        }); 

$(".toggle_button[value='initiated']").parents("div.output_area").insertBefore($(".toggle_button[value='initiated']").parents("div.output").find('div.output_area').first());
    var shown = $(".toggle_button[value='initiated']").parents("div.cell.code_cell").find('div.input').is(':visible');
    var title = ((shown) ? 'Hide ' : 'Show ') + 'code'; 
     $(".toggle_button[value='initiated']").addClass("init_show");
            hidden_cells.addClass("init_hidden");  $(".toggle_button[value='initiated']").val(title);
        </script></div></div>
</div>
<p>PCA has picked out the orthogonal directions of maximum and minimum spread, shown by the black arrows. Let’s also have a look at the corresponding eigenvalues:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Eigenvalues:&#39;</span><span class="p">,</span> <span class="n">eig_values</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="s1">&#39;Standard deviations:&#39;</span><span class="p">,</span> <span class="p">(</span><span class="n">eig_values</span><span class="o">**</span><span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>

<span class="n">toggle_code</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Eigenvalues: [2.08 0.01] Standard deviations: [1.44 0.07]
</pre></div>
</div>
<div class="output text_html">
    <script>
      function get_new_label(butn, hide) {
          var shown = !($(hide).is(':visible'))
          var title = $(butn).val().substr($(butn).val().indexOf(" ") + 1)
          return ((shown) ? 'Hide ' : 'Show ') + title
      }
      function code_toggle(butn, hide) {
          $(butn).val(get_new_label(butn,hide));
          $(hide).slideToggle();
      };
    </script>
    <input type="submit" value='initiated' class='toggle_button'>
    <script>
        $(".toggle_button[value='initiated']").click(function(){
            code_toggle(this, $(this).parents('div.cell.code_cell').find('div.input'))
        }); 

$(".toggle_button[value='initiated']").parents("div.output_area").insertBefore($(".toggle_button[value='initiated']").parents("div.output").find('div.output_area').first());
    var shown = $(".toggle_button[value='initiated']").parents("div.cell.code_cell").find('div.input').is(':visible');
    var title = ((shown) ? 'Hide ' : 'Show ') + 'code'; 
     $(".toggle_button[value='initiated']").addClass("init_show");
        $(".toggle_button[value='initiated']").parents('div.code_cell').find('div.input').addClass("init_hidden");  $(".toggle_button[value='initiated']").val(title);
    </script></div></div>
</div>
<p>The roots of the eigenvalues, <span class="math notranslate nohighlight">\(1.44, 0.07\)</span>, are the standard deviations of the dataset along the corresponding directions, and appear plausible from the plot. We can easily apply the same idea to MNIST, and plot the reconstruction error against the number of components discarded, for all images of the character <span class="math notranslate nohighlight">\(8\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;mnist_images.npy&#39;</span><span class="p">)</span> <span class="c1"># load the MNIST images...</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;mnist_labels.npy&#39;</span><span class="p">)</span> <span class="c1"># ... and labels</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y</span> <span class="o">==</span> <span class="mi">8</span><span class="p">)]</span> <span class="c1"># select all images of 8s</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="c1"># reshape images into vectors</span>

<span class="n">eig_values</span><span class="p">,</span> <span class="n">eig_vectors</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="c1"># apply PCA</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">eig_values</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">eig_values</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">])[::</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;black&#39;</span><span class="p">)</span>
<span class="n">beautify_plot</span><span class="p">({</span><span class="s2">&quot;title&quot;</span><span class="p">:</span><span class="s2">&quot;Mean reconstruction error&quot;</span><span class="p">,</span> <span class="s2">&quot;x&quot;</span><span class="p">:</span><span class="s2">&quot;No. of components kept (M)&quot;</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">:</span><span class="s2">&quot;$E_</span><span class="si">{rms}</span><span class="s2">$&quot;</span><span class="p">})</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">toggle_code</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/dim_red_pca_8_0.svg" src="../../_images/dim_red_pca_8_0.svg" /><div class="output text_html">
    <script>
      function get_new_label(butn, hide) {
          var shown = !($(hide).is(':visible'))
          var title = $(butn).val().substr($(butn).val().indexOf(" ") + 1)
          return ((shown) ? 'Hide ' : 'Show ') + title
      }
      function code_toggle(butn, hide) {
          $(butn).val(get_new_label(butn,hide));
          $(hide).slideToggle();
      };
    </script>
    <input type="submit" value='initiated' class='toggle_button'>
    <script>
        $(".toggle_button[value='initiated']").click(function(){
            code_toggle(this, $(this).parents('div.cell.code_cell').find('div.input'))
        }); 

$(".toggle_button[value='initiated']").parents("div.output_area").insertBefore($(".toggle_button[value='initiated']").parents("div.output").find('div.output_area').first());
    var shown = $(".toggle_button[value='initiated']").parents("div.cell.code_cell").find('div.input').is(':visible');
    var title = ((shown) ? 'Hide ' : 'Show ') + 'code'; 
     $(".toggle_button[value='initiated']").addClass("init_show");
        $(".toggle_button[value='initiated']").parents('div.code_cell').find('div.input').addClass("init_hidden");  $(".toggle_button[value='initiated']").val(title);
    </script></div></div>
</div>
<p>The reconstruction error appears to be dominated by a few components, whilst most components are relatively poor descriptors of the data. Let’s visualise these components below:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">12</span><span class="p">):</span>
    
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">eig_vectors</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]),</span> <span class="n">cmap</span> <span class="o">=</span> <span class="s1">&#39;binary&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mi">27</span><span class="p">,</span> <span class="mi">27</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;cyan&#39;</span><span class="p">,</span> <span class="n">fontsize</span> <span class="o">=</span> <span class="mi">16</span><span class="p">,</span>
             <span class="n">horizontalalignment</span> <span class="o">=</span> <span class="s1">&#39;right&#39;</span><span class="p">,</span> <span class="n">verticalalignment</span> <span class="o">=</span> <span class="s1">&#39;bottom&#39;</span><span class="p">)</span>
    <span class="n">remove_axes</span><span class="p">()</span>
    
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">toggle_code</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/dim_red_pca_10_0.svg" src="../../_images/dim_red_pca_10_0.svg" /><div class="output text_html">
    <script>
      function get_new_label(butn, hide) {
          var shown = !($(hide).is(':visible'))
          var title = $(butn).val().substr($(butn).val().indexOf(" ") + 1)
          return ((shown) ? 'Hide ' : 'Show ') + title
      }
      function code_toggle(butn, hide) {
          $(butn).val(get_new_label(butn,hide));
          $(hide).slideToggle();
      };
    </script>
    <input type="submit" value='initiated' class='toggle_button'>
    <script>
        $(".toggle_button[value='initiated']").click(function(){
            code_toggle(this, $(this).parents('div.cell.code_cell').find('div.input'))
        }); 

$(".toggle_button[value='initiated']").parents("div.output_area").insertBefore($(".toggle_button[value='initiated']").parents("div.output").find('div.output_area').first());
    var shown = $(".toggle_button[value='initiated']").parents("div.cell.code_cell").find('div.input').is(':visible');
    var title = ((shown) ? 'Hide ' : 'Show ') + 'code'; 
     $(".toggle_button[value='initiated']").addClass("init_show");
        $(".toggle_button[value='initiated']").parents('div.code_cell').find('div.input').addClass("init_hidden");  $(".toggle_button[value='initiated']").val(title);
    </script></div></div>
</div>
<p>This plot shows the principal components for the images of <span class="math notranslate nohighlight">\(8\)</span>’s in the dataset, arranged by eigenvalue size. All of them display a figure of <span class="math notranslate nohighlight">\(8\)</span> shape, with slight deformations and different pixel intensities along the figure of <span class="math notranslate nohighlight">\(8\)</span>. We can also look directly at how a certain sample is composed of such compoents, by computing the image approximation using <span class="math notranslate nohighlight">\(M\)</span> components:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">no_components</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">]</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">12</span><span class="p">))</span>
<span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">test_image</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">X</span><span class="p">[:</span><span class="mi">10</span><span class="p">]):</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">M</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">no_components</span><span class="p">):</span>
        <span class="n">inner_products</span> <span class="o">=</span> <span class="p">(</span><span class="n">eig_vectors</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">test_image</span><span class="p">)</span>

        <span class="n">weights</span> <span class="o">=</span> <span class="n">inner_products</span><span class="p">[:</span><span class="n">M</span><span class="p">]</span>
        <span class="n">vectors</span> <span class="o">=</span> <span class="n">eig_vectors</span><span class="p">[:,</span> <span class="p">:</span><span class="n">M</span><span class="p">]</span>
        <span class="n">reconstructed_img</span> <span class="o">=</span> <span class="n">vectors</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>

        <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="n">j</span><span class="o">*</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">no_components</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">reconstructed_img</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]),</span> <span class="n">cmap</span> <span class="o">=</span> <span class="s1">&#39;binary&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mi">27</span><span class="p">,</span> <span class="mi">27</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="n">M</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;cyan&#39;</span><span class="p">,</span> <span class="n">fontsize</span> <span class="o">=</span> <span class="mi">14</span><span class="p">,</span>
                 <span class="n">horizontalalignment</span> <span class="o">=</span> <span class="s1">&#39;right&#39;</span><span class="p">,</span> <span class="n">verticalalignment</span> <span class="o">=</span> <span class="s1">&#39;bottom&#39;</span><span class="p">)</span>
        <span class="n">remove_axes</span><span class="p">()</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="n">j</span><span class="o">*</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">no_components</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">no_components</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">test_image</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]),</span> <span class="n">cmap</span> <span class="o">=</span> <span class="s1">&#39;binary&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mi">27</span><span class="p">,</span> <span class="mi">27</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="s1">&#39;True&#39;</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;cyan&#39;</span><span class="p">,</span> <span class="n">fontsize</span> <span class="o">=</span> <span class="mi">12</span><span class="p">,</span>
                 <span class="n">horizontalalignment</span> <span class="o">=</span> <span class="s1">&#39;right&#39;</span><span class="p">,</span> <span class="n">verticalalignment</span> <span class="o">=</span> <span class="s1">&#39;bottom&#39;</span><span class="p">)</span>
    <span class="n">remove_axes</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">(</span><span class="n">w_pad</span> <span class="o">=</span> <span class="o">-</span><span class="mi">25</span><span class="p">,</span> <span class="n">h_pad</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">toggle_code</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/dim_red_pca_12_0.svg" src="../../_images/dim_red_pca_12_0.svg" /><div class="output text_html">
    <script>
      function get_new_label(butn, hide) {
          var shown = !($(hide).is(':visible'))
          var title = $(butn).val().substr($(butn).val().indexOf(" ") + 1)
          return ((shown) ? 'Hide ' : 'Show ') + title
      }
      function code_toggle(butn, hide) {
          $(butn).val(get_new_label(butn,hide));
          $(hide).slideToggle();
      };
    </script>
    <input type="submit" value='initiated' class='toggle_button'>
    <script>
        $(".toggle_button[value='initiated']").click(function(){
            code_toggle(this, $(this).parents('div.cell.code_cell').find('div.input'))
        }); 

$(".toggle_button[value='initiated']").parents("div.output_area").insertBefore($(".toggle_button[value='initiated']").parents("div.output").find('div.output_area').first());
    var shown = $(".toggle_button[value='initiated']").parents("div.cell.code_cell").find('div.input').is(':visible');
    var title = ((shown) ? 'Hide ' : 'Show ') + 'code'; 
     $(".toggle_button[value='initiated']").addClass("init_show");
        $(".toggle_button[value='initiated']").parents('div.code_cell').find('div.input').addClass("init_hidden");  $(".toggle_button[value='initiated']").val(title);
    </script></div></div>
</div>
<p>As the number of components used increases, the approximate image progressively resembles the true image. Although at first sight the variability between different writings of the character <span class="math notranslate nohighlight">\(8\)</span> might appear quite large, this example illustrates that the important degrees of freedom are much fewer than the number of dimensions in the dataset.</p>
<p>Having covered principal component analysis, you should now understand:</p>
<ol class="simple">
<li><p>The equation for PCA and how it is derived.</p></li>
<li><p>Why reconstruction loss minimisation is equivalent to variance maximisation.</p></li>
</ol>
<p>In <a class="reference internal" href="dim_red_hd.html"><span class="doc std std-doc">section 4.2</span></a> we will look at more computationally effective ways of implementing PCA with high dimensional data.</p>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./content/dimensionality_reduction"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Stratis Markou, Rich Turner<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../../_static/js/index.d3f166471bb80abb5163.js"></script>


    
  </body>
</html>