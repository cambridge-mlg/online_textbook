
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>The effects of model complexity: overfitting and generalisation in regression &#8212; Probabilistic Modelling and Inference</title>
    
  <link rel="stylesheet" href="../../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom_style.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/.ipynb_checkpoints/custom_style-checkpoint.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../index.html">
  
  <img src="../../_static/logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Probabilistic Modelling and Inference</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../home.html">
   Online Inference Textbook
  </a>
 </li>
</ul>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="regression-intro.html">
   Regression
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="regression-linear.html">
     Linear regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="regression-nonlinear.html">
     Non-linear basis regression
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/content/regression/regression_overfitting.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/cambridge-mlg/online_textbook/master?urlpath=tree/./content/regression/regression_overfitting.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#diagnosing-under-fitting-and-over-fitting-training-and-validation-sets">
   Diagnosing under-fitting and over-fitting: training and validation sets
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#summary">
   Summary
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#questions">
   Questions
  </a>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = &#39;svg&#39; # change output plot display format to &#39;svg&#39;

<span class="c1"># import the required modules for this notebook</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># import the helper functions from the parent directory,</span>
<span class="c1"># these help with things like graph plotting and notebook layout</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;..&#39;</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">helper_functions</span> <span class="kn">import</span> <span class="o">*</span>

<span class="c1"># set things like fonts etc - comes from helper_functions</span>
<span class="n">set_notebook_preferences</span><span class="p">()</span>

<span class="c1"># add a show/hide code button - also from helper_functions</span>
<span class="n">toggle_code</span><span class="p">(</span><span class="n">title</span> <span class="o">=</span> <span class="s2">&quot;setup code&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>.output {
    font-family: ariel;
    align-items: normal;
    text-align: normal;
}

div.output_svg div { margin : auto; }
.div.output_area.MathJax_Display{ text-align: center; }
div.text_cell_render { font-family: sans-serif; }

details {
    margin: 20px 0px;
    padding: 0px 10px;
    border-radius: 3px;
    border-style: solid;
    border-color: black;
    border-width: 2px;
}
details div{padding: 20px 30px;}
details summary{font-size: 18px;}

table {
     margin: calc(auto + 10px) !important;
     border: solid !important;
 }

 th, td {
    text-align: left !important;
 }

 .further_box {
    background-color:rgb(230, 230, 230);
    border-style: solid;
    margin: 10px 10px 10px 0px;
    padding: 10px;
    left:calc(auto - 20px);
 }

 .question_box {
    background-color:rgb(255, 255, 225);
    border-style: solid;
    margin: 10px 10px 10px 0px;
    padding: 10px;
    left:calc(auto - 20px);
 }</style>
     <input type="submit" value='Home' id="initiated" class='home_button' onclick='window.location="../index.ipynb"' style='float: right; margin-right: 40px;'>
    <script>
    $('.home_button').not('#initiated').remove();
    $('.home_button').removeAttr('id');
    $(".home_button").insertBefore($("div.cell").first());

    $('div.input.init_hidden').hide()
    $('div.input.init_shown').show()
    $('.toggle_button').each(function( index, element ) {
       var prefix;
       if (this.classList.contains('init_show')) {
           prefix = 'Show '
       }
       else if (this.classList.contains('init_hide')) {
           prefix = 'Hide '
       };
       $(this).val(prefix + $(this).val().substr($(this).val().indexOf(" ") + 1))
    });
    IPython.OutputArea.prototype._should_scroll = function(lines) {
        return false;
    }
    </script>
</div><div class="output text_html">
    <script>
      function get_new_label(butn, hide) {
          var shown = $(butn).parents("div.cell.code_cell").find('div.input').is(':visible');
          var title = $(butn).val().substr($(butn).val().indexOf(" ") + 1)
          return ((shown) ? 'Show ' : 'Hide ') + title
      }
      function code_toggle(butn, hide) {
        $(butn).val(get_new_label(butn,hide));
        $(hide).slideToggle();
      };
    </script>
    <input type="submit" value='initiated' class='toggle_button'>
    <script>
        var hide_area = $(".toggle_button[value='initiated']").parents('div.cell').prevAll().addBack().slice(-1)
        hide_area = $(hide_area).find("div.input").add($(hide_area).filter("div.text_cell"))
        $(".toggle_button[value='initiated']").prop("hide_area", hide_area)
        $(".toggle_button[value='initiated']").click(function(){
            code_toggle(this, $(this).prop("hide_area"))
        }); 
$(".toggle_button[value='initiated']").parents("div.output_area").insertBefore($(".toggle_button[value='initiated']").parents("div.output").find('div.output_area').first());
    var shown = $(".toggle_button[value='initiated']").parents("div.cell.code_cell").find('div.input').is(':visible');
    var title = ((shown) ? 'Hide ' : 'Show ') + 'setup code'; 
     $(".toggle_button[value='initiated']").addClass("init_show");
            $(hide_area).addClass("init_hidden");  $(".toggle_button[value='initiated']").val(title);
    </script></div></div>
</div>
<div class="section" id="the-effects-of-model-complexity-overfitting-and-generalisation-in-regression">
<h1>The effects of model complexity: overfitting and generalisation in regression<a class="headerlink" href="#the-effects-of-model-complexity-overfitting-and-generalisation-in-regression" title="Permalink to this headline">¶</a></h1>
<p><span class="xref myst">Previously</span> we have fit polynomial functions to regression data using the least squares and maximum likelihood approaches. In this section we will explore one of the problems with these estimation techniques: overfitting.</p>
<p>Returning to our simple 1D regression dataset, let’s fit a polynomial model</p>
<p>\begin{align}
y_n = f_{\mathbf{w}}(x_n) + \sigma_y \epsilon_n = \sum_{d=0}^D w_d x^d_n + \sigma_y \epsilon_n ;; \text{where} ;; \epsilon \sim \mathcal{N}(0,1)
\end{align}</p>
<p>and vary the order of the polynomial <span class="math notranslate nohighlight">\(D = 1, 2, ... 9\)</span>. Below are the resulting maximum likelihood fits of the underlying function <span class="math notranslate nohighlight">\(f_{\mathbf{w}}(x)\)</span> shown in black:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_nonlin</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;reg_nonlin_x.npy&#39;</span><span class="p">)</span> <span class="c1"># load inputs from a prepared non-linear dataset</span>
<span class="n">y_nonlin</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;reg_nonlin_y.npy&#39;</span><span class="p">)</span> <span class="c1"># load corresponding outputs</span>
<span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span> <span class="c1"># 100 points equispaced between 0 and 1</span>


<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">9</span><span class="p">))</span> <span class="c1"># figure on which to plot the subfigures - you don&#39;t have to worry about this</span>

<span class="k">for</span> <span class="n">D</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">):</span>

    <span class="n">phi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">x_</span> <span class="o">**</span> <span class="n">d</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">D</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span> <span class="k">for</span> <span class="n">x_</span> <span class="ow">in</span> <span class="n">x_nonlin</span><span class="p">])</span> <span class="c1"># training design matrix, as before</span>
    
    <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">((</span><span class="n">phi</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">phi</span><span class="p">))</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">phi</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">y_nonlin</span><span class="p">)</span> <span class="c1"># Moore-Penrose pseudoinverse</span>
    
    <span class="n">phi_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">x_</span> <span class="o">**</span> <span class="n">d</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">D</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span> <span class="k">for</span> <span class="n">x_</span> <span class="ow">in</span> <span class="n">xs</span><span class="p">])</span> <span class="c1"># design matrix of evaluation points as before</span>
    
    <span class="n">ys</span> <span class="o">=</span> <span class="n">phi_pred</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w</span><span class="p">)</span> <span class="c1"># model predictions as before</span>
    
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">D</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x_nonlin</span><span class="p">,</span> <span class="n">y_nonlin</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;red&#39;</span><span class="p">)</span> <span class="c1"># plot </span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;black&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.25</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.4</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="s1">&#39;D = &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">D</span><span class="p">),</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">fontsize</span> <span class="o">=</span> <span class="mi">12</span><span class="p">,</span>
                 <span class="n">horizontalalignment</span> <span class="o">=</span> <span class="s1">&#39;right&#39;</span><span class="p">,</span> <span class="n">verticalalignment</span> <span class="o">=</span> <span class="s1">&#39;bottom&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="o">-</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">D</span> <span class="o">%</span> <span class="mi">3</span> <span class="ow">is</span> <span class="ow">not</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">remove_axes</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">D</span> <span class="o">&lt;</span> <span class="mi">7</span><span class="p">:</span>
        <span class="n">remove_axes</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">toggle_code</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/regression_overfitting_2_0.svg" src="../../_images/regression_overfitting_2_0.svg" /><div class="output text_html">
    <script>
      function get_new_label(butn, hide) {
          var shown = $(butn).parents("div.cell.code_cell").find('div.input').is(':visible');
          var title = $(butn).val().substr($(butn).val().indexOf(" ") + 1)
          return ((shown) ? 'Show ' : 'Hide ') + title
      }
      function code_toggle(butn, hide) {
        $(butn).val(get_new_label(butn,hide));
        $(hide).slideToggle();
      };
    </script>
    <input type="submit" value='initiated' class='toggle_button'>
    <script>
        var hide_area = $(".toggle_button[value='initiated']").parents('div.cell').prevAll().addBack().slice(-1)
        hide_area = $(hide_area).find("div.input").add($(hide_area).filter("div.text_cell"))
        $(".toggle_button[value='initiated']").prop("hide_area", hide_area)
        $(".toggle_button[value='initiated']").click(function(){
            code_toggle(this, $(this).prop("hide_area"))
        }); 
$(".toggle_button[value='initiated']").parents("div.output_area").insertBefore($(".toggle_button[value='initiated']").parents("div.output").find('div.output_area').first());
    var shown = $(".toggle_button[value='initiated']").parents("div.cell.code_cell").find('div.input').is(':visible');
    var title = ((shown) ? 'Hide ' : 'Show ') + 'code'; 
     $(".toggle_button[value='initiated']").addClass("init_show");
            $(hide_area).addClass("init_hidden");  $(".toggle_button[value='initiated']").val(title);
    </script></div></div>
</div>
<p>The plots show that, for low order polynomials, there is structure in the data which is not captured by the regression function. This is called <strong>underfitting</strong>. As the order of the polynomial increases, the model becomes more flexible and the fitted curve <span class="math notranslate nohighlight">\(f(x)\)</span> can pass closer to each datapoint thereby reducing the cost function. Intermediate settings of <span class="math notranslate nohighlight">\(D\)</span> lead to well fit models. The most complex model (\(D = 9\)) has \(10\) degrees of freedom (including the constant \(w_0\)), which is equal to the number of datapoints. This provides the model with enough degrees of freedom for the polynomial to pass exactly through every data point achieving a cost of 0.</p>
<p>Although the <span class="math notranslate nohighlight">\(D=9\)</span> solution has minimised our training cost, intuitively it looks poor. Do we really expect such an extreme polynomial to accurately predict unseen test data? This phenomenon is called <strong>overfitting</strong> and it is a serious problem that can occur when the model complexity becomes large compared to the amount of training data. Maximum likelihood fitting is particularly succeptible to this phenomenon. Overfitted models exhibit very small training errors but are too well adapted for the training data and <em>learn the noise</em> of that data too. Consequently, they make poor predictions about unseen datapoints \(-\) they fail to generalise.</p>
<div class="section" id="diagnosing-under-fitting-and-over-fitting-training-and-validation-sets">
<h2>Diagnosing under-fitting and over-fitting: training and validation sets<a class="headerlink" href="#diagnosing-under-fitting-and-over-fitting-training-and-validation-sets" title="Permalink to this headline">¶</a></h2>
<p>How can we automatically evaluate model performance and diagnose overfitting? One useful approach is to use only a subset of the data to train the model (the training set) leaving out a portion of the data to assess the fit (the <strong>validation set</strong>). The model’s performance on the train and validation sets can be compared to diagnose overfitting: if predictions made on the training set are accurate, but those made on the test set are poor, it is likely that there is overfitting. Note that setting aside some data for validation does mean that there are fewer data to train on, potentially reducing the quality of the predictions. There are a wide range of refinements to this basic <a href="https://en.wikipedia.org/wiki/Cross-validation_(statistics)"><strong>cross validation</strong></a> approach.</p>
<p>Let’s use a validation set comprising 40 unseen data points to assess the quality of the models fit above.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_ext</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;reg_nonlin_x_extended.npy&#39;</span><span class="p">)</span>
<span class="n">y_ext</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;reg_nonlin_y_extended.npy&#39;</span><span class="p">)</span>
<span class="n">x_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">x_ext</span><span class="p">[:</span><span class="mi">10</span><span class="p">],</span> <span class="n">x_ext</span><span class="p">[</span><span class="mi">10</span><span class="p">:],</span> <span class="n">y_ext</span><span class="p">[:</span><span class="mi">10</span><span class="p">],</span> <span class="n">y_ext</span><span class="p">[</span><span class="mi">10</span><span class="p">:]</span>
<span class="n">D_max</span> <span class="o">=</span> <span class="mi">9</span><span class="p">;</span>
<span class="n">train_err</span><span class="p">,</span> <span class="n">test_err</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span> <span class="c1"># lists to store training and test error as D varies</span>
<span class="k">for</span> <span class="n">D</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">D_max</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
    
    <span class="n">phi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">x_</span> <span class="o">**</span> <span class="n">d</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">D</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span> <span class="k">for</span> <span class="n">x_</span> <span class="ow">in</span> <span class="n">x_train</span><span class="p">])</span> <span class="c1"># design matrix for training points</span>
    
    <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span> <span class="p">(</span><span class="n">phi</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">phi</span><span class="p">)</span> <span class="p">,</span> <span class="p">(</span><span class="n">phi</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span> <span class="p">)</span>
    
    <span class="n">y_trained</span> <span class="o">=</span> <span class="n">phi</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w</span><span class="p">)</span> <span class="c1"># evaluate polynomial at training points</span>
    
    <span class="n">train_err</span><span class="o">.</span><span class="n">append</span><span class="p">(((</span><span class="n">y_trained</span> <span class="o">-</span> <span class="n">y_train</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">**</span> <span class="mf">0.5</span><span class="p">)</span> <span class="c1"># store train errors</span>
    
    <span class="n">phi_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">x_</span> <span class="o">**</span> <span class="n">d</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">D</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span> <span class="k">for</span> <span class="n">x_</span> <span class="ow">in</span> <span class="n">x_test</span><span class="p">])</span> <span class="c1"># design matrix for test points</span>
    
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">phi_pred</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w</span><span class="p">)</span> <span class="c1"># evaluate polynomial at test data points</span>
    
    <span class="n">test_err</span><span class="o">.</span><span class="n">append</span><span class="p">(((</span><span class="n">y_pred</span> <span class="o">-</span> <span class="n">y_test</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">**</span><span class="mf">0.5</span><span class="p">)</span> <span class="c1"># store test errors</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">matplotlib</span><span class="o">.</span><span class="n">pyplot</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">D_max</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">train_err</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;Train&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">D_max</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">test_err</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;Validation&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_yscale</span><span class="p">(</span><span class="s2">&quot;log&quot;</span><span class="p">)</span>

<span class="n">beautify_plot</span><span class="p">({</span><span class="s2">&quot;title&quot;</span><span class="p">:</span><span class="s2">&quot;Training and validation errors&quot;</span><span class="p">,</span> <span class="s2">&quot;x&quot;</span><span class="p">:</span><span class="s2">&quot;$D$&quot;</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">:</span> <span class="s1">&#39;RMS Error&#39;</span><span class="p">})</span> <span class="c1"># add a legend for maximum style</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">toggle_code</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/regression_overfitting_5_0.svg" src="../../_images/regression_overfitting_5_0.svg" /><div class="output text_html">
    <script>
      function get_new_label(butn, hide) {
          var shown = $(butn).parents("div.cell.code_cell").find('div.input').is(':visible');
          var title = $(butn).val().substr($(butn).val().indexOf(" ") + 1)
          return ((shown) ? 'Show ' : 'Hide ') + title
      }
      function code_toggle(butn, hide) {
        $(butn).val(get_new_label(butn,hide));
        $(hide).slideToggle();
      };
    </script>
    <input type="submit" value='initiated' class='toggle_button'>
    <script>
        var hide_area = $(".toggle_button[value='initiated']").parents('div.cell').prevAll().addBack().slice(-1)
        hide_area = $(hide_area).find("div.input").add($(hide_area).filter("div.text_cell"))
        $(".toggle_button[value='initiated']").prop("hide_area", hide_area)
        $(".toggle_button[value='initiated']").click(function(){
            code_toggle(this, $(this).prop("hide_area"))
        }); 
$(".toggle_button[value='initiated']").parents("div.output_area").insertBefore($(".toggle_button[value='initiated']").parents("div.output").find('div.output_area').first());
    var shown = $(".toggle_button[value='initiated']").parents("div.cell.code_cell").find('div.input').is(':visible');
    var title = ((shown) ? 'Hide ' : 'Show ') + 'code'; 
     $(".toggle_button[value='initiated']").addClass("init_show");
            $(hide_area).addClass("init_hidden");  $(".toggle_button[value='initiated']").val(title);
    </script></div></div>
</div>
<p>As the order of the polynomial increases, the training error steadily decreases due to the model’s increased flexibility, whereas the validation error initially decreases and then increases again. For low <span class="math notranslate nohighlight">\(D\)</span> there is a small difference between train and validation errors indicating a small amount of overfitting. By <span class="math notranslate nohighlight">\(D=8\)</span> the model has started to significantly overfit the training data and no longer makes sensible predictions on the validation set.</p>
</div>
<div class="section" id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h2>
<p><strong>Overfitting</strong> occurs when a training procedure causes a model to capture aspects of the training data that are irrelevant or deleterious for predicting unseen test data.</p>
<p>Overfitting can be monitored by comparing the quality of predictions on the <strong>training set</strong> and a held-out <strong>validation set</strong>. A validation error that is much larger than the test error reveals overfitting.</p>
<p>Having learned how to diagnose and quantify overfitting, in the next section we investigate how to use <a class="reference internal" href="regression_regularisation.html"><span class="doc std std-doc">regularisation</span></a> to mitigate its effects.</p>
</div>
<div class="section" id="questions">
<h2>Questions<a class="headerlink" href="#questions" title="Permalink to this headline">¶</a></h2>
<ol class="simple">
<li><p>Make a plot of the training and validation errors for a Gaussian basis function model. Instead of changing the number of basis functions, choose D=10 and alter the width of the basis function. Comment on the role of the width in the context of the complexity of the model.</p></li>
</ol>
<details>
<summary>Answer</summary>
<div>
The width of the Gaussian basis function controls the typical length-scale over which the regression function changes. It therefore controls the flexibility of the model and with it the model's susceptibility to overfitting. Notice that for short length-scales, more basis functions may be required to obtain a sensible fit. 
</div>
</details>
<ol class="simple">
<li><p>An experimenter uses a single validation set to evaluate i) many different choices of basis function <span class="math notranslate nohighlight">\(\phi_d(x)\)</span>, ii) many different orders of model <span class="math notranslate nohighlight">\(D\)</span>, and iii) many different hyper parameter settings e.g. <span class="math notranslate nohighlight">\(\sigma_{\mathbf{w}}\)</span>. They choose to use the model with the smallest validation error to make predictions on a test set. They are surprised that the resulting predictions are poor - after all they used a validation set to guard against overfitting. What has happened? How could they have improved their approach?</p></li>
</ol>
<details>
<summary>Answer</summary>
<div>
The experimenter has overfit the _validation set_. If the validation set is used to decide amongst a very large set of models, it is perfectly possible to overfit at this second level model fitting. 
<p>Approaches that might help in this case are i) <a href="https://en.wikipedia.org/wiki/Cross-validation_(statistics)#k-fold_cross-validation">k-fold cross validation</a> (which effective increases the size of the validation set), and ii) <a class="reference external" href="https://en.wikipedia.org/wiki/Ensemble_learning">ensembling</a> (averaging) model predictions rather than taking the best one. Another option would be to build a large model that contains the individual model as special cases and use Bayesian inference for fitting.</p>
</div>
</details></div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./content/regression"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Stratis Markou, Rich Turner<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../../_static/js/index.3da636dd464baa7582d2.js"></script>


    
  </body>
</html>